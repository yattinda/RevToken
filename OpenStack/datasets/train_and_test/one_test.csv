label,status,file_dir,change_id,change_num,patch_set,shaped_code,before_code,after_code,line,ref
1,1,nova/pci/stats.py,I91dd7993395f693c7d26c1caa44fa365f5cbec12,778350,4,fields PciDeviceType VDPA ,                fields.PciDeviceType.VDPA):,"        ):\n            fields.PciDeviceType.VDPA,\n        ):",229,refs/changes/50/778350/4
1,1,nova/virt/libvirt/driver.py,If02a263055376442a116d00c18a1599b436f21d2,741545,2, NOTE lyarwood Volume drivers are now loaded on demand,        # NOTE(lyarwood): Volume drivers are now loaded on-demand,"        self.volume_drivers = ty.Dict[str, volume.LibvirtBaseVolumeDriver]\n        # NOTE(lyarwood): Volume drivers are loaded on-demand\n        self.volume_drivers = ty.Dict[str, volume.LibvirtBaseVolumeDriver]",328,refs/changes/45/741545/2
1,1,nova/compute/api.py,I7f3cbc57a374b2f271018a2f6ef33ef579798db8,780333,1, so this proably works but block evac with vdpa until tested ,        # so this proably works but block evac with vdpa until tested.,"        if instance.has_vdpa_ports():\n        # so this probably works, but we block evac with vdpa until tested.\n        if instance.has_vdpa_ports():",5293,refs/changes/33/780333/1
1,1,nova/conductor/tasks/migrate.py,Ia500b105b9ec70c0d8bd38faa084270b825476eb,680394,2, request or we failed ot claim resources on every alternate,        # request or we failed ot claim resources on every alternate,"        # if we reach this point then none of the hosts was new enough for the\n        # request or we failed to claim resources on every alternate\n        reason = (""Exhausted all hosts available during compute service level """,276,refs/changes/94/680394/2
1,1,nova/objects/instance_numa.py,I6cd206542fdd28f3ef551dcc727f4cb35a53f6a3,724381,1,if nova object name not in primitive ,        if 'nova_object.name' not in primitive:,"        """"""\n    @classmethod\n    def _migrate_legacy_object(cls, context, instance_uuid, primitive):",142,refs/changes/81/724381/1
1,1,nova/cmd/status.py,I0dc2044286dbe78314c650a92c4654f7f50642d2,603499,2,return upgradecheck UpgradeCheckResult upgradecheck UpgradeCheckCode FAILURE msg ,"            return upgradecheck.UpgradeCheckResult(upgradecheck.UpgradeCheckCode.FAILURE, msg)","            return upgradecheck.Result(upgradecheck.Code.FAILURE, msg)\n            return upgradecheck.Result(upgradecheck.Code.FAILURE, msg)\n",115,refs/changes/99/603499/2
1,1,nova/tests/functional/test_servers.py,Ib50b6b02208f5bd2972de8a6f8f685c19745514c,676140,18, check that server is allocates from the new host properly,        # check that server is allocates from the new host properly,        # check that server allocates from the new host properly\n        # check that server allocates from the new host properly\n,6616,refs/changes/40/676140/18
1,1,nova/tests/unit/virt/libvirt/test_driver.py,I0ea3a0a1342ef53ed891c145561eb7402f553a8b,728481,4,objects InstanceNUMACell ,                           objects.InstanceNUMACell(,"                id=0, cpuset=set([0]), pcpuset=set(), memory=1024),\n            objects.InstanceNUMACell(\n",3794,refs/changes/81/728481/4
1,1,nova/tests/functional/api/openstack/placement/fixtures/placement.py,I126ada549d3879f89d1ec64b743da14807a39351,568359,1,it s teardown ,    it's teardown.,    its teardown.\n    its teardown.\n,28,refs/changes/59/568359/1
1,1,nova/tests/functional/api_sample_tests/test_servers.py,Ia3dea78f16cb3c7081714c4db36e20d5ee76ed7d,745906,2,ADMIN API True,    ADMIN_API = True,\nVALID_DISK_CACHEMODES = [\n,978,refs/changes/06/745906/2
1,1,nova/tests/unit/conductor/tasks/test_migrate.py,Ia500b105b9ec70c0d8bd38faa084270b825476eb,680394,2,mock claim resources assert has calls ,        mock_claim_resources.assert_has_calls([,"            self.context, task.reportclient, task.request_spec,\n        mock_claim_resources.assert_called_once_with(\n            self.context, task.reportclient, task.request_spec,",669,refs/changes/94/680394/2
1,1,nova/tests/unit/virt/libvirt/volume/test_quobyte.py,Iba30c49f108af9055de1b1a5c7b1a8406d66cf1a,648093,2,def tearDown self ,    def tearDown(self):,\nPROJECT_READER_OR_SYSTEM_READER = PROJECT_READER + ' or ' + SYSTEM_READER\n,65,refs/changes/93/648093/2
1,1,nova/api/openstack/placement/objects/resource_provider.py,I89d2892fabb6273bfa793f4a06dced80b68e93d5,588350,1,LOG debug s d of d returned d matches ,"            LOG.debug(""%s (%d of %d) returned %d matches"",","                      str(request), str(suffix), len(alloc_reqs))\n            LOG.debug(""%s (suffix '%s') returned %d matches"",\n                      str(request), str(suffix), len(alloc_reqs))",4043,refs/changes/50/588350/1
1,1,nova/virt/powervm/mgmt.py,I2691b09d95691915dc1065284d25ad22db41d32b,543023,9,from nova privsep import path as priv path,from nova.privsep import path as priv_path,"\ndef generate_snapshot_metadata(context, image_api, image_id, instance):\n",26,refs/changes/23/543023/9
1,1,nova/api/openstack/placement/objects/resource_provider.py,I1d9bf27f49306032929274446cf3952bd42e4f8c,566166,1,class MatchSpec object ,class MatchSpec(object):,"    candidates are matched.\nclass CandidateSearchContext(object):\n    """"""An object keeping certain lookups and caches for when allocation",3725,refs/changes/66/566166/1
1,1,nova/tests/unit/virt/libvirt/test_driver.py,Ib9f735216773224f91ac7f49fbe2eee119670872,652104,5,r neutron physnet bar numa nodes option was defined ,"                r""'\[neutron_physnet_bar\] numa_nodes' option was defined."",","                ""was listed in '[neutron] physnets' but no corresponding ""\n                ""'[neutron_physnet_bar] numa_nodes' option was defined."",\n",15769,refs/changes/04/652104/5
1,1,nova/tests/functional/test_servers.py,Idf785fd80f9f507c7f8d2bc762b09fe1527aa5f2,676972,17, check that server is allocates from the final host properly while,        # check that server is allocates from the final host properly while,        # check that server allocates from the final host properly while\n        # check that server allocates from the final host properly while\n,6685,refs/changes/72/676972/17
1,1,nova/notifications/objects/image.py,I36ea5d5e677ab3e6c88223b20f5377e9471c55db,698613,2, hw mem encryption image meta pros hw mem encryption ,"        'hw_mem_encryption': ('image_meta_pros', 'hw_mem_encryption'),","        'hw_mem_encryption': ('image_meta_props', 'hw_mem_encryption'),\n        'hw_mem_encryption': ('image_meta_props', 'hw_mem_encryption'),\n",134,refs/changes/13/698613/2
1,1,nova/api/validation/extra_specs/hw.py,Ib64a1348cce1dca995746214616c4f33d9d664bd,704643,2, topology of the guest ,            'topology of the guest.',            'The number of virtual CPU cores to emulate per socket in the '\n            'guest CPU topology.'\n,218,refs/changes/43/704643/2
1,1,nova/virt/libvirt/driver.py,I043880cb81b02488d13c3387d696142545c13395,770533,7,if self supports vdpa ,        if self._supports_vdpa():,            libvirt.VIR_CONNECT_LIST_NODE_DEVICES_CAP_NET |\n            libvirt.VIR_CONNECT_LIST_NODE_DEVICES_CAP_PCI_DEV\n        ),7409,refs/changes/33/770533/7
1,1,nova/virt/libvirt/driver.py,I0ea3a0a1342ef53ed891c145561eb7402f553a8b,728481,4,if object numa cell cpu pinning and,        if (object_numa_cell.cpu_pinning and,"            pin_cpuset.cpuset = set([inst_cell.cpu_pinning[vcpu]])\n        # 'InstanceNUMACell.cpu_pinning' tracks the CPU pinning pair for guest\n        # CPU and host CPU. If the guest CPU is in the keys of 'cpu_pinning',",4985,refs/changes/81/728481/4
1,1,nova/objects/instance_mapping.py,Ia30405de4bf8e8ac07b942e44b05a868a18eb80a,582536,1,LOG error InstanceMapping not found unable to populate ,"            LOG.error('InstanceMapping not found, unable to populate',",            LOG.error(msg)\n            # This could happen for existing instances before\n            # nova-manage cell_v2 map_instances is run.,192,refs/changes/36/582536/1
1,1,nova/scheduler/utils.py,I6e15c6507d037ffe263a460441858ed454b02504,628163,1,cpu multipliers append float val ,                cpu_multipliers.append(float(val)),"    return value\n        value = utils.validate_num_values(\n            aggregate_vals, multiplier_config, cast_to=float)",1049,refs/changes/63/628163/1
1,1,nova/virt/powervm/disk/driver.py,Id3a2a1df3746120af38b62fdc902c3c0c44c38ee,549053,6,pass,        pass,        raise NotImplementedError()\n        raise NotImplementedError()\n,242,refs/changes/53/549053/6
1,1,nova/tests/unit/virt/libvirt/test_driver.py,Id9184c4ef301ef48534e4c104b073a2d3731133b,571993,4,mock commit assert not called ,        mock_commit.assert_not_called(),                flags=fakelibvirt.VIR_DOMAIN_BLOCK_REBASE_RELATIVE)\n            mock_commit.assert_not_called()\n,21298,refs/changes/93/571993/4
1,1,nova/tests/functional/libvirt/test_vgpu.py,Ib5dbcee295d8a78b9a55806054de6265c3663343,717975,8,self assertEqual fakelibvirt PGPU<NUMBER> PCI ADDR parent name ,"        self.assertEqual(fakelibvirt.PGPU1_PCI_ADDR, parent_name)",            mdevs = list(mdevs.keys())\n            # Now get the detailed information about this single mdev\n            mdev_info = self.compute1.driver._get_mediated_device_information(,251,refs/changes/75/717975/8
1,1,nova/compute/manager.py,Ia1b3ab0b66fdaf569f6c7a09510f208ee28725b2,680107,1,if numa topology not in instance or,            if ('numa_topology' not in instance or,\n            if not (instance.numa_topology and\n                        instance.numa_topology.cpu_pinning_requested):,827,refs/changes/07/680107/1
1,1,nova/virt/powervm/disk/driver.py,Id3a2a1df3746120af38b62fdc902c3c0c44c38ee,549053,6,pass,        pass,        raise NotImplementedError()\n        raise NotImplementedError()\n,279,refs/changes/53/549053/6
1,1,nova/scheduler/client/report.py,I66d69327d3361825ca0b44b46744b97ea3069eb1,639653,2, There is not enough inventory left on s RP ,                                'There is not enough inventory left on %s RP ',                                'resources.' % (\n                                'There is not enough inventory left on %s '\n                                'resource provider to remove %d amount of %s ',1700,refs/changes/53/639653/2
1,1,nova/cmd/manage.py,I6b80021a2f90d3379c821dc8f02a72f350169eb3,774896,4,print str e ,            print(_(str(e))),            print(str(e))\n            print(str(e))\n,2833,refs/changes/96/774896/4
1,1,nova/virt/libvirt/driver.py,I146cc9d4caafd0abd6b2642edb6eb59cd7e339b7,634549,10,for ns conf in CONF libvirt pmem namespace sizes ,            for ns_conf in CONF.libvirt.pmem_namespace_sizes:,        # pmem name list group by label\n        pmem_names_by_label = collections.defaultdict(list)\n        if CONF.libvirt.pmem_namespaces:,434,refs/changes/49/634549/10
1,1,nova/tests/functional/api_sample_tests/test_servers.py,Ia3dea78f16cb3c7081714c4db36e20d5ee76ed7d,745906,2,ADMIN API True,    ADMIN_API = True,\nVALID_DISK_CACHEMODES = [\n,1001,refs/changes/06/745906/2
1,1,nova/policies/base.py,I999f8d84e10ff1a57c1ff6b717801b495032e358,645452,8,PROJECT MEMBER OR SYSTEM ADMIN PROJECT MEMBER or SYSTEM ADMIN,PROJECT_MEMBER_OR_SYSTEM_ADMIN = PROJECT_MEMBER + 'or' + SYSTEM_ADMIN,PROJECT_READER_OR_SYSTEM_READER = PROJECT_READER + ' or ' + SYSTEM_READER\nPROJECT_MEMBER_OR_SYSTEM_ADMIN = PROJECT_MEMBER + ' or ' + SYSTEM_ADMIN\nPROJECT_READER_OR_SYSTEM_READER = PROJECT_READER + ' or ' + SYSTEM_READER,35,refs/changes/52/645452/8
1,1,nova/api/openstack/compute/server_password.py,Ic0b16608078e4545f546509df94caba3166ed6e2,660950,10,self compute api compute API args kwargs ,"        self.compute_api = compute.API(*args, **kwargs)","    def __init__(self):\n        super(ServerPasswordController, self).__init__()\n        self.compute_api = compute.API()",28,refs/changes/50/660950/10
1,1,nova/tests/functional/api/openstack/placement/test_direct.py,I075785abcd4f4a8e180959daeadf215b9cd175c8,572576,1,with direct PlacementDirect CONF as url session ,"        with direct.PlacementDirect(CONF) as (url, session):",            resp = client.get('/resource_providers')\n        with direct.PlacementDirect(CONF) as client:\n            resp = client.get('/resource_providers'),48,refs/changes/76/572576/1
1,1,nova/compute/provider_tree.py,If37aaff1e3652692fd0750e98612f3b040019042,678449,3,return True,        return True,            self.resources = copy.deepcopy(resources)\n            return True\n,234,refs/changes/49/678449/3
1,1,nova/notifications/base.py,I649d8a27baa8840bc1bb567fef027c749c663432,536243,1,user id context user id ,"        user_id=context.user_id,","        action_initiator = context.user_id,\n        user_id=instance.user_id,\n",407,refs/changes/43/536243/1
1,1,nova/compute/api.py,I69b6e153324a3e5680e096cd714e5d4dd05bae34,680158,4, reject sev instances live migrate ,    @reject_sev_instances('live_migrate'),    @reject_sev_instances(instance_actions.LIVE_MIGRATION)\n    @reject_sev_instances(instance_actions.LIVE_MIGRATION)\n,4460,refs/changes/58/680158/4
1,1,nova/tests/functional/test_servers.py,I1222fc21bde4158df1db70370c7f3bd319ec081f,699065,3,qos normal port qos sriov port self flavor with group policy ,"            qos_normal_port, qos_sriov_port, self.flavor_with_group_policy)",\n        # Use a custom weigher to make sure that we have a predictable host\n,7501,refs/changes/65/699065/3
1,1,nova/scheduler/client/report.py,I097732754b67bd5cf50abd15db7da3f013b6cdd5,583667,1,return resp json consumer generation ,            return resp.json()['consumer_generation'],"\n                          ""or a temporary occurrence as compute nodes start ""\n",1483,refs/changes/67/583667/1
1,1,nova/virt/libvirt/driver.py,I2ef7c5bef87bd64c087f3b136c2faac9a3865f10,774240,1,flag flag strip ,                flag = flag.strip('-'),                            policy='disable'))\n                flag = flag.lstrip('-')\n                cpu.add.feature(,705,refs/changes/40/774240/1
1,1,nova/tests/unit/virt/libvirt/test_host.py,I2c7b183fcb01f3cb67cb1c8b8bea7aaf5ce424f3,770532,7,def test get vdpa nodedev by address self ,    def test_get_vdpa_nodedev_by_address(self):,    def test_get_vdpa_device_path(self):\n    def test_get_vdpa_device_path(self):\n,1245,refs/changes/32/770532/7
1,1,nova/compute/manager.py,Id553242d61eb167a58cdbea75423a5acf3ca7467,714653,4,filters host self host,            filters['host'] = self.host,\n        result = self.cli.heal_allocations(cell_uuid=cell_uuid)\n,679,refs/changes/53/714653/4
1,1,nova/tests/unit/policies/test_quota_sets.py,I5b692cc15d763d4ae4ce8dd1ad1e83a83e0ab434,719128,2, Check that everyone is able to revert the quota to default ,        # Check that everyone is able to revert the quota to default.,        # their own quota.\n        # Check that everyone is able to get the default quota or\n        # their own quota.,49,refs/changes/28/719128/2
1,1,nova/tests/unit/virt/libvirt/test_imagecache.py,Ib2c406327fef2fb4868d8050fc476a7d17706e23,727224,5,from io import StringIO,from io import StringIO,import io\nimport io\n,18,refs/changes/24/727224/5
1,1,nova/conf/scheduler.py,I38f9e0bce5bc58d8b03f562f0de618f1ec38aeb1,556762,2,for hosts with group soft affinity Only a positive value are meaningful as,"  for hosts with group soft affinity. Only a positive value are meaningful, as","* An integer or float value, where the value corresponds to a weight multiplier\n  for hosts with group soft affinity. Only a positive value is meaningful, as\n",521,refs/changes/62/556762/2
1,1,nova/conductor/manager.py,I9358cc3cff44b81b5ce8f9917417282f83860c5b,566470,1, param exception the thrown exception in case of failure ,    :param exception: the thrown exception (in case of failure),    :param exc: the raised exception (in case of failure)\n    :param exc: the raised exception (in case of failure)\n,102,refs/changes/70/566470/1
1,1,nova/tests/functional/test_servers.py,Id4684093e8bdf3b61667490443e3d2f6ed65f4b3,756530,16, start a second compute to show that resources only allocated from,        # start a second compute to show that resources only allocated from,        # start a second compute to show that resources are only allocated from\n        # start a second compute to show that resources are only allocated from\n,6147,refs/changes/30/756530/16
1,1,nova/tests/unit/policies/test_admin_password.py,Ic6e1fb081fe61262f718efc045b3b3f28694e8a7,710813,2, role member and project id project id s ,"                ""role:member and project_id:%(project_id)s""",\n                       fatal=False):\n,140,refs/changes/13/710813/2
1,1,nova/tests/unit/virt/powervm/test_image.py,Iba75282db968f74ac2e4474c872ba59f9cd77652,568988,1,with mock patch object six moves builtins open mock open ,"        with mock.patch.object(six.moves.builtins, 'open', mock_open):","        with mock.patch.object(six.moves.builtins, 'open', new=mock_open):\n        with mock.patch.object(six.moves.builtins, 'open', new=mock_open):\n",31,refs/changes/88/568988/1
1,1,nova/conductor/manager.py,Ie49d605c66062d2548241d7e04f5a2a6b98c011e,569498,5,LOG warning ,                LOG.warning(,        if missing_traits:\n            LOG.error(\n,1053,refs/changes/98/569498/5
1,1,nova/api/openstack/compute/migrate_server.py,I09cac780b9ee5b5726874d4e6f895fd0cd4bff8c,680395,3,else ,            else:,            # Train\n\n            # TODO(gibi): Remove when nova only supports compute newer than,72,refs/changes/95/680395/3
1,1,nova/scheduler/client/report.py,I9064a2598d773a814269995eed8862d093d9100e,533821,3,self set aggregates for provider uuid newp aggregates ,"            self.set_aggregates_for_provider(uuid, newp.aggregates)","                self.set_traits_for_provider(uuid, newp.traits)\n                self.set_aggregates_for_provider(uuid, newp.aggregates)\n",1357,refs/changes/21/533821/3
1,1,nova/scheduler/request_filter.py,I667f56612d7f63834863476694cb1f4c71a58302,749068,2,for requested network in requested networks or ,    for requested_network in requested_networks or []:,    for requested_network in requested_networks:\n    for requested_network in requested_networks:\n,305,refs/changes/68/749068/2
1,1,nova/api/openstack/compute/floating_ips.py,I131062ded9ddedc31cf3b448b2c38306b55e874b,703973,3,except Exception as e ,            except Exception as e:,\n        # LiveMigrationTask._find_destination call updated the\n,287,refs/changes/73/703973/3
1,1,nova/virt/powervm/disk/driver.py,Id3a2a1df3746120af38b62fdc902c3c0c44c38ee,549053,6,pass,        pass,        raise NotImplementedError()\n        raise NotImplementedError()\n,242,refs/changes/53/549053/6
1,1,nova/image/download/rbd.py,I3032bbe6bd2d6acc9ba0f0cac4d00ed4b4464ceb,574301,1,import logging,import logging,from six.moves import urllib\nimport oslo_log import log as logging\nfrom six.moves import urllib,15,refs/changes/01/574301/1
1,1,nova/db/sqlalchemy/api_migrations/migrate_repo/versions/062_update_aggregate_metadata_key_value_index.py,Ifc020015daff0d2e20d6f8b1069b028115d66b35,587704,1, Change aggregate metadata key index to cover key value ,"    """"""Change aggregate metadata (key) index to cover (key, value).""""""","    """"""Change aggregate_metadata (key) index to cover (key, value).""""""\n    """"""Change aggregate_metadata (key) index to cover (key, value).""""""\n",23,refs/changes/04/587704/1
1,1,nova/tests/functional/api_sample_tests/test_servers.py,Ia3dea78f16cb3c7081714c4db36e20d5ee76ed7d,745906,2,ADMIN API True,    ADMIN_API = True,\nVALID_DISK_CACHEMODES = [\n,231,refs/changes/06/745906/2
1,1,nova/tests/unit/virt/libvirt/fakelibvirt.py,I8e349849db0b1a540d295c903f1470917b82fd97,746981,1,FAKE QEMU VERSION <NUMBER>,FAKE_QEMU_VERSION = 4000000,    libvirt_driver.MIN_QEMU_VERSION)\nFAKE_QEMU_VERSION = versionutils.convert_version_to_int(\n    libvirt_driver.MIN_QEMU_VERSION),184,refs/changes/81/746981/1
1,1,nova/scheduler/utils.py,Idd58298a6b01775f962b9bf0a0835f762c8e0ed2,769720,2,self ResourceRequest ,        self = ResourceRequest(),        rr = cls()\n        rr = cls()\n,123,refs/changes/20/769720/2
1,1,nova/virt/block_device.py,I4205c00311f389907dcc390869414687ac03b7f5,682378,1,context instance volume api self volume size wait func ,"                context, instance, volume_api, self.volume_size, wait_func,","                wait_func=wait_func, snapshot=snapshot)\n                context, instance, volume_api, self.volume_size,\n                wait_func=wait_func, snapshot=snapshot)",761,refs/changes/78/682378/1
1,1,nova/tests/unit/virt/libvirt/fakelibvirt.py,I2c7b183fcb01f3cb67cb1c8b8bea7aaf5ce424f3,770532,7,VIR CONNECT LIST NODE DEVICES CAP VDPA <NUMBER>,VIR_CONNECT_LIST_NODE_DEVICES_CAP_VDPA = 131072,VIR_CONNECT_LIST_NODE_DEVICES_CAP_VDPA = 1 << 17\nVIR_CONNECT_LIST_NODE_DEVICES_CAP_VDPA = 1 << 17\n,184,refs/changes/32/770532/7
1,1,nova/scheduler/client/report.py,Ie991d4b53e9bb5e7ec26da99219178ab7695abf6,591810,2, param source consumer uuid the UUID of the consumer that s allocation,        :param source_consumer_uuid: the UUID of the consumer that's allocation,                                     allocations\n        :param source_consumer_uuid: the UUID of the consumer from which\n                                     allocations are moving,1826,refs/changes/10/591810/2
1,1,nova/scheduler/client/report.py,I35f98f88f8353602e1bfc135f35d1b7bc9ba42a4,653145,2,if resp status code <NUMBER> ,        if resp.status_code == 200:,        if resp:\n        if resp:\n,2362,refs/changes/45/653145/2
1,1,nova/tests/unit/compute/test_multi_cell_list.py,Id1a0538de4cc3235680579ffa0ecf7f4eb24a1dd,594577,6, with an error,        # with an error,\n                if host.cell_uuid != cell_uuid:\n,340,refs/changes/77/594577/6
1,1,nova/scheduler/client/report.py,I66d69327d3361825ca0b44b46744b97ea3069eb1,639653,2, works here as this function re query the allocations ,                # works here as this function (re)query the allocations.,                # works here as this function (re)queries the allocations.\n                # works here as this function (re)queries the allocations.\n,1738,refs/changes/53/639653/2
1,1,nova/scheduler/filters/core_filter.py,Ibfbfdae9e6ec93f772631a84e8969f4e11da8aee,673496,1, allocation ratios either per host in the nova conf ,                    'allocation ratios either per host in the nova.conf',                    'filter_scheduler driver. Operators should define cpu '\n                    'allocation ratios either per host in the nova.conf '\n                    'or via the placement API.'),40,refs/changes/96/673496/1
1,1,nova/virt/libvirt/driver.py,Ia8a35ecff20911471a5c353c0b55be86f2e4e21a,631237,1, param cells An list of LibvirtConfigCapsNUMACell objects ,        :param cells: An list of ``LibvirtConfigCapsNUMACell`` objects.,        :param cells: A list of ``LibvirtConfigCapsNUMACell`` objects.\n        :param cells: A list of ``LibvirtConfigCapsNUMACell`` objects.\n,6422,refs/changes/37/631237/1
1,1,nova/compute/manager.py,I43e995c3f5d71e56f0b0e136e45a307e329d7ae4,598084,5,timeout CONF instance delete interval <NUMBER>,        timeout = CONF.instance_delete_interval * 2,\n    except OSError as e:\n,7789,refs/changes/84/598084/5
1,1,nova/conf/scheduler.py,I38f9e0bce5bc58d8b03f562f0de618f1ec38aeb1,556762,2, An integer or float value where the value corresponds to weight multiplier,"* An integer or float value, where the value corresponds to weight multiplier","  for hosts with group soft affinity. Only a positive value is meaningful, as\n* An integer or float value, where the value corresponds to a weight multiplier\n  for hosts with group soft affinity. Only a positive value is meaningful, as",520,refs/changes/62/556762/2
1,1,nova/image/glance.py,I20913201cf945a7fde1f9e6264c415e1235db7b9,738738,2, param write image Write the image file provided by image chunks ,        :param write_image: Write the image file provided by image_chunks.,        :param dst_path: Filepath to transfer the image file to.\n        :param dst_path: Filepath to transfer the image file to.\n,342,refs/changes/38/738738/2
1,1,nova/api/openstack/compute/views/servers.py,I55bf78e63f68f8167249edc3327b024d9ecb0af2,679181,1,unknown only None,                unknown_only = None,"                # API.\n                unknown_only = self._get_unknown_only(context)\n                # If we're not allowed by policy to show host status at all,",416,refs/changes/81/679181/1
1,1,nova/tests/functional/test_report_client.py,I433700e833f97c0fec946dafc2cdda9d49e1100b,558911,2, proving a WSGI application to be intercepted but it will also need to,"# proving a WSGI application to be intercepted, but it will also need to","# need to be responsible for having a reasonable persistence layer\n# providing a WSGI application to be intercepted, but it will also\n# need to be responsible for having a reasonable persistence layer",22,refs/changes/11/558911/2
1,1,nova/tests/unit/api/openstack/compute/test_images.py,Ifca9d9b766c87d4e1107e9be07223f8d4a0d6794,606845,1, OS EXT IMG SIZE size <NUMBER> ,"                      'OS-EXT-IMG-SIZE:size': '25165824',","                      'OS-EXT-IMG-SIZE:size': 25165824,\n                      'OS-EXT-IMG-SIZE:size': 25165824,\n",82,refs/changes/45/606845/1
1,1,nova/tests/functional/api_sample_tests/test_servers.py,Ia3dea78f16cb3c7081714c4db36e20d5ee76ed7d,745906,2,ADMIN API True,    ADMIN_API = True,\nVALID_DISK_CACHEMODES = [\n,231,refs/changes/06/745906/2
1,1,nova/compute/api.py,Ife3c7a5a95c5d707983ab33fd2fbfc1cfb72f676,688802,1,context instance uuid force True ,"                context, instance.uuid, force=True)","                context, instance.uuid)\n                context, instance.uuid)\n",2321,refs/changes/02/688802/1
1,1,nova/tests/functional/db/test_instance_mapping.py,Ia30405de4bf8e8ac07b942e44b05a868a18eb80a,582536,1,self context <NUMBER> <NUMBER> <NUMBER> <NUMBER> <NUMBER> ,"            self.context, '00000000-0000-0000-0000-000000000000')","        self.assertEqual(uuids[5], marker.project_id)\n            self.context, instance_mapping.FAKE_UUID)\n        self.assertEqual(uuids[5], marker.project_id)",170,refs/changes/36/582536/1
1,1,nova/compute/api.py,I7f3cbc57a374b2f271018a2f6ef33ef579798db8,780333,1,search opts ,        search_opts = {,"        # so this probably works, but we block evac with vdpa until tested.\n        if instance.has_vdpa_ports():\n",3970,refs/changes/33/780333/1
1,1,nova/objects/network_request.py,Icb295bbd8c83e2e340a7ac3ecc1f159e0db7c7b1,564442,1, tunneled fields BooleanField nullable True ,"        'tunneled': fields.BooleanField(nullable=True),","        'tunneled': fields.BooleanField(default=False),\n        'tunneled': fields.BooleanField(default=False),\n",44,refs/changes/42/564442/1
1,1,nova/compute/resource_tracker.py,Ieeaad9783e0ff93377fbc6c7932618d2fac8946a,615677,2, it s not already there ,        # it's not already there.,"        # By clearing the report client's cache, we force _update to go looking\n        # for the compute node provider's record in placement, creating it if\n        # it's not already there. Otherwise _update could skip querying",808,refs/changes/77/615677/2
1,1,nova/tests/unit/virt/libvirt/test_driver.py,I0ea3a0a1342ef53ed891c145561eb7402f553a8b,728481,4,mock patch object ,"                mock.patch.object(host.Host, 'has_min_version',","            mock.patch.object(host.Host, 'has_min_version', return_value=True),\n            mock.patch.object(host.Host, 'has_min_version', return_value=True),\n",3905,refs/changes/81/728481/4
1,1,nova/tests/unit/api/openstack/compute/test_server_migrations.py,I4636a8d270ce01c1831bc951c4497ad472bc9aa8,573136,4,class ServerMigrationsTestsV<NUMBER> ServerMigrationsTestsV<NUMBER> ,class ServerMigrationsTestsV263(ServerMigrationsTestsV21):,    wsgi_api_version = '2.64'\nclass ServerMigrationsTestsV264(ServerMigrationsTestsV224):\n    wsgi_api_version = '2.64',322,refs/changes/36/573136/4
1,1,nova/tests/functional/api_sample_tests/test_cells.py,Iddb519008515f591cf1d884872a5887afbe766f2,651291,1,self assertEqual <NUMBER> ex response status code ,"        self.assertEqual(410, ex.response.status_code)","                          self.api.api_delete, 'os-cells/cell3',\n                          check_response_state=[410])\n",26,refs/changes/91/651291/1
1,1,nova/tests/unit/virt/libvirt/test_driver.py,I0ea3a0a1342ef53ed891c145561eb7402f553a8b,728481,4,mock patch object ,                mock.patch.object(,"                return_value=instance_topology),\n            mock.patch.object(\n                objects.InstanceNUMATopology, ""get_by_instance_uuid"",",3905,refs/changes/81/728481/4
1,1,nova/virt/hardware.py,I24ab1034c84608181a18bd4c64e3e83acd2b40b2,716271,1,raise exception Invalid ,        raise exception.Invalid(,        raise exception.RequiredMixedOrRealtimeCPUMask\n        raise exception.RequiredMixedOrRealtimeCPUMask\n,1991,refs/changes/71/716271/1
1,1,nova/conf/cyborg.py,Iee0766269d61948ad701911e8b0e5e24d3d6eb04,631242,1,ks loading get auth plugin conf options v<NUMBER>password ,            ks_loading.get_auth_plugin_conf_options('v2password') +,\n                    vifs = [vif.source_vif for vif in migrate_data.vifs\n,63,refs/changes/42/631242/1
1,1,nova/virt/libvirt/driver.py,I573396116e10cf87f80f1ded55f2cd8f498859e4,710785,2,run as root True ,                                            run_as_root=True),"                info = images.privileged_qemu_img_info(\n                    path, output_format='json')\n",1960,refs/changes/85/710785/2
1,1,nova/utils.py,I00d29e9fd80e6b8f7ba3bbd8e82dde9d4cb1522f,555282,1, param host The name of the host to which the server is evacuated ,    :param host: The name of the host to which the server is evacuated.,    :param host: The name of the compute host.\n    :param host: The name of the compute host.\n,1391,refs/changes/82/555282/1
1,1,nova/tests/functional/db/api/test_migrations.py,Ifc020015daff0d2e20d6f8b1069b028115d66b35,587704,1,def check <NUMBER> self engine ,"    def _check_062(self, engine):","    def _check_062(self, engine, data):\n    def _check_062(self, engine, data):\n",723,refs/changes/04/587704/1
1,1,nova/conductor/manager.py,Ie49d605c66062d2548241d7e04f5a2a6b98c011e,569498,5, traits required in image meta properties ,                'traits_required' in image_meta.properties):,        if ('properties' not in image_meta or\n                'traits_required' not in image_meta.properties):\n            return,1028,refs/changes/98/569498/5
1,1,nova/tests/unit/scheduler/test_utils.py,Iff84fcba02a4b6d7717f4b387e392593f2983118,728482,4,return value set <NUMBER> <NUMBER> ,"                return_value=set([2, 3]))","        """"""\n                new=mock.Mock(return_value={2, 3}))\n    def test_resource_request_init_with_mixed_cpus_isolate_emulator(self):",1086,refs/changes/82/728482/4
1,1,nova/config.py,Id7c2f0b53c8871ff47a836ec4c324c8cce430b79,564440,1, register neutron numa opts ,    _register_neutron_numa_opts(),    # TODO(stephenfin): Move this to nova/compute/manager.py\n    _register_dynamic_opts()\n,65,refs/changes/40/564440/1
1,1,nova/tests/fixtures.py,I4a32a688c7ceb05c263a0e93a91fb9b8ff0c65d4,683609,1, A fixture to temporary fix oslo messaging bug <NUMBER> by using,"    """"""A fixture to temporary fix oslo.messaging bug #1529084 by using","\n                context, instance, volume_api, self.volume_size,\n",2153,refs/changes/09/683609/1
1,1,nova/compute/resource_tracker.py,I033e8269194de54432079cbc970431e3dcea7ce5,672106,4, except the AggregateCoreFilter and related RAM and disk filters now ,"        # except the AggregateCoreFilter and related RAM and disk filters now,","        # about dropping the fields from the 'ComputeNode' object entirely\n        # except 'Aggregate(Core|Ram|Disk)Filter', the 'os-hypervisors' API,\n        # and perhaps some out-of-tree filters. Once the in-tree stuff is",1057,refs/changes/06/672106/4
1,1,nova/compute/manager.py,I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a,623543,39,dev rp name dev rp name ,                dev_rp_name = dev_rp['name'],\n                dev_rp_name = self.reportclient.get_resource_provider_name(\n,2160,refs/changes/43/623543/39
1,1,nova/api/openstack/placement/handlers/resource_provider.py,Ic7f4ea6f97f6bd434cf7338dec9ce7db40a300a6,595453,1,<NUMBER> microversions <NUMBER> <NUMBER> response with an empty body,    200 (microversions 1.20 - ) response with an empty body,    On success return a 201 response with an empty body\n    (microversions 1.0 - 1.19) or a 200 response with a\n    payload representing the newly created resource provider,80,refs/changes/53/595453/1
1,1,nova/api/metadata/base.py,Iebf54d06cb1a2043bf13685c95c2589d35e04b24,580742,2,seen ,        seen = [],        seen = set()\n        seen = set()\n,498,refs/changes/42/580742/2
1,1,nova/virt/libvirt/driver.py,I1c31cfd317d089026fa30d401157f661b6049cd3,666914,6,valid buses blockinfo VALID STORAGE BUS get ,        valid_buses = blockinfo.VALID_STORAGE_BUS.get(,"            ""COMPUTE_STORAGE_BUS"")\n        traits = LibvirtDriver._project_traits(\n            blockinfo.VALID_STORAGE_BUS, CONF.libvirt.virt_type,",9642,refs/changes/14/666914/6
1,1,nova/tests/unit/virt/libvirt/test_driver.py,I8014ea3e047b103086fbba9d4f8b988b8506577e,563984,4,def test live migration copy disk paths self mock xml ,"    def test_live_migration_copy_disk_paths(self, mock_xml,",\n        with mock.patch(\n,9837,refs/changes/84/563984/4
1,1,nova/conf/devices.py,I4681931a6fdd2bfc52b9d5729f84c3994f650fc9,564214,2,If you miss to provide PCI addresses for each section an,"If you miss to provide PCI addresses for each section, an","     device_addresses = 0000:86:00.0\nIf you fail to provide PCI addresses for each section, an\n",45,refs/changes/14/564214/2
1,1,nova/scheduler/weights/ram.py,I6e15c6507d037ffe263a460441858ed454b02504,628163,1,return utils get weight multiplier host state cpu ,"        return utils.get_weight_multiplier(host_state, 'cpu')","            CONF.filter_scheduler.ram_weight_multiplier)\n        return utils.get_weight_multiplier(\n            host_state, 'ram_weight_multiplier',",35,refs/changes/63/628163/1
1,1,nova/virt/libvirt/driver.py,I6a1cebb6676b20b76e451fc3bde5ea54bbf16ff7,715489,5, reshape functional test,            # reshape functional test,            # FIXME(sbauza): No longer accept the parent value to be nullable\n            # once we fix the reshape functional test\n,6928,refs/changes/89/715489/5
1,1,nova/virt/fake.py,I4ab96095106b38737ed355fcad07e758f8b5a9b0,687140,5,return cached ,            return 'cached',            return True\n            return True\n,1028,refs/changes/40/687140/5
1,1,nova/compute/manager.py,Ia01c3602e764a3941d435ed779e311127d33914e,549130,2,attachment id self volume api attachment create ,            attachment_id = self.volume_api.attachment_create(,                attachment_id = self.volume_api.attachment_create(\n                attachment_id = self.volume_api.attachment_create(\n,619,refs/changes/30/549130/2
1,1,nova/api/openstack/api_version_request.py,Ic98e01ef5385606792f25f261e36f551386033ae,566473,1, <NUMBER> <NUMBER> Add PENDING in InstanceState ,    * 2.63 - Add PENDING in InstanceState.,             ``PENDING`` state is mapped to the ``ERROR`` state.\n    * 2.63 - Add support for applying trusted certificates when creating or\n             rebuilding a server.,151,refs/changes/73/566473/1
1,1,nova/tests/functional/test_servers.py,Id78627c5c08090de6220249a5f44d26bf32724af,684545,1,def fake orig claim ,        def fake_orig_claim(,\n    Note that this weigher is supposed to be used via\n,3362,refs/changes/45/684545/1
1,1,nova/tests/unit/virt/test_hardware.py,Id3441073adde563a568c9550df53690d1e6c998a,674395,1,pinned cpus set ,"            pinned_cpus=set([]),","            pinned_cpus=set(),\n            pinned_cpus=set(),\n",2772,refs/changes/95/674395/1
1,1,nova/virt/libvirt/volume/net.py,If642103dbe5f74048b5e2263652d8e9cf7899177,590188,1,new size self connector extend volume connection info data ,        new_size = self.connector.extend_volume(connection_info['data']),\n                    if not disk:\n,155,refs/changes/88/590188/1
1,1,nova/conf/libvirt.py,I71bf4c5b5be4dbc89a28bf243b7d11cf1d612ab4,618491,2, Syntax is guest gid host gid count ,                     'Syntax is guest-gid:host-gid:count.',                     'Syntax is guest-gid:host-gid:count. '\n                     'Syntax is guest-gid:host-gid:count. '\n,695,refs/changes/91/618491/2
1,1,nova/compute/resource_tracker.py,I39d93dbf8552605e34b9f146e3613e6af62a1774,576462,1, of auto correction allocations ,"                ""of auto-correction allocations. "")","                ""auto-correction of allocations."")\n                ""auto-correction of allocations."")\n",1232,refs/changes/62/576462/1
1,1,nova/tests/functional/test_servers.py,Idf785fd80f9f507c7f8d2bc762b09fe1527aa5f2,676972,17, and the instance is allocation from the source host,        # and the instance is allocation from the source host,        # and the instance allocates from the source host\n        # and the instance allocates from the source host\n,6750,refs/changes/72/676972/17
1,1,nova/api/openstack/placement/objects/consumer.py,Id609789ef6b4a4c745550cde80dd49cabe03869a,567678,3,def create incomplete consumers ctx ,def create_incomplete_consumers(ctx):,"def create_incomplete_consumers(ctx, batch_size):\ndef create_incomplete_consumers(ctx, batch_size):\n",29,refs/changes/78/567678/3
1,1,nova/quota.py,Ifa7df0c6b9d0042f51c0e9fc27a946870f780a44,614783,3, instances if CONF api instance list per project cells is True and,    # instances if CONF.api.instance_list_per_project_cells is True and,    # variant that makes this native to nova.context.\n    # instances. We could optimize this to avoid the CellMappingList query\n    # for single-cell deployments by checking the cell cache and only doing,1172,refs/changes/83/614783/3
1,1,nova/compute/resource_tracker.py,I880e9daa6b97d73a0e33ac9a5bdae9bacfa89aaa,585928,1,cn memory mb used CONF reserved host ,        cn.memory_mb_used = CONF.reserved_host_,        cn.memory_mb_used = CONF.reserved_host_memory_mb\n        cn.memory_mb_used = CONF.reserved_host_memory_mb\n,1159,refs/changes/28/585928/1
1,1,nova/compute/manager.py,Ia9ea1e164fb3b4a386405538eed58d94ad115172,563505,6,from concurrent import futures as c futures,from concurrent import futures as c_futures,"from concurrent import futures\n# If py2, concurrent.futures comes from the futures library otherwise it\n# comes from the py3 standard library.",30,refs/changes/05/563505/6
1,1,nova/policies/volumes.py,I37fa825b0e915e83da7023564a29811dcdfa058d,742777,1,This API is proxy calls to the Volume service This is deprecated ,"This API is proxy calls to the Volume service. This is deprecated."""""",","This API is a proxy call to the Volume service. It is deprecated."""""",\nThis API is a proxy call to the Volume service. It is deprecated."""""",\n",42,refs/changes/77/742777/1
1,1,nova/tests/unit/virt/powervm/tasks/test_storage.py,I2691b09d95691915dc1065284d25ad22db41d32b,543023,9, Management Partition is VIOS and Novalink hosted storage,        # Management Partition is VIOS and Novalink hosted storage,        # Management Partition is VIOS and NovaLink hosted storage\n        # Management Partition is VIOS and NovaLink hosted storage\n,233,refs/changes/23/543023/9
1,1,nova/scheduler/utils.py,I32d9704fe19bc85e06a613b6dffb99f00003315e,641289,1, There are more than one numbered request group in the ,"                ""There are more than one numbered request group in the ""","                ""There is more than one numbered request group in the ""\n                ""There is more than one numbered request group in the ""\n",311,refs/changes/89/641289/1
1,1,nova/compute/manager.py,Ifd76289964d513e9544544e5787f5f8999589475,589085,2,allocations self reportclient get allocations for consumer ,        allocations = self.reportclient.get_allocations_for_consumer(,"            context, instance.uuid)['allocations']\n        allocations = self.reportclient.get_allocs_for_consumer(\n            context, instance.uuid)['allocations']",4675,refs/changes/85/589085/2
1,1,nova/conf/libvirt.py,I06e1f7429c056c4ce8506b10359762e457dbb2a0,670298,2,hardware Specifying models with CPU features that are emulated by qemu could,hardware. Specifying models with CPU features that are emulated by qemu could,.. note::\n    Be careful to only specify models which can be fully supported in\n    hardware.,569,refs/changes/98/670298/2
1,1,nova/tests/functional/libvirt/test_vgpu.py,I018762335b19c98045ad42147080203092b51c27,712741,2,current host host<NUMBER> ,    current_host = 'host1',"    _current_host = _DEFAULT_HOST\n    # Since we run all computes by a single process, we need to identify which\n    # current compute service we use at the moment.",40,refs/changes/41/712741/2
1,1,nova/policies/remote_consoles.py,Ic81da0ebc23d6526c5ca2d9d98159e07f3e53822,716484,2,This policy is for POST remote consoles API and below Server actions APIs,This policy is for POST /remote-consoles API and below Server actions APIs,This policy is for ``POST /remote-consoles`` API and below Server actions APIs\nThis policy is for ``POST /remote-consoles`` API and below Server actions APIs\n,30,refs/changes/84/716484/2
1,1,nova/tests/unit/policies/test_attach_interfaces.py,I8a91db6c13710b693b3b4a3d002fd2ac09fcf3f3,705126,8,It defines the set of context with scopped token,    It defines the set of context with scopped token,    It defines the set of context with scoped token\n    It defines the set of context with scoped token\n,114,refs/changes/26/705126/8
1,1,nova/scheduler/filters/core_filter.py,Ibfbfdae9e6ec93f772631a84e8969f4e11da8aee,673496,1, filter scheduler driver Operators should define cpu ,                    'filter_scheduler driver. Operators should define cpu',                    'using the Placement service when using the '\n                    'filter_scheduler driver. Operators should define cpu '\n                    'allocation ratios either per host in the nova.conf ',39,refs/changes/96/673496/1
1,1,nova/scheduler/request_filter.py,Ibf62c5398a95c75fde815309e7a4f82f1bd9649c,657629,1,from oslo utils import excutils,from oslo_utils import excutils,\n            # NOTE(johnthetubaguy) this should eventually fail a\n,17,refs/changes/29/657629/1
1,1,nova/tests/unit/compute/test_compute.py,I49618a6dafbe00b9516ff37172b6aea68a42deba,567522,1,self assertFalse mock warning called ,        self.assertFalse(mock_warning.called),        mock_warning.assert_not_called()\n        mock_warning.assert_not_called()\n,3582,refs/changes/22/567522/1
1,1,nova/tests/functional/api_sample_tests/test_attach_interfaces.py,I09420ff7134874dfe4dc399931c7740e81ecc2d0,631948,4, Tests for the <NUMBER> <NUMBER> microversion in the os attach interfaces API,"    """"""Tests for the 2.68 microversion in the os-attach-interfaces API","class AttachInterfacesSampleV268JsonTest(AttachInterfacesSampleJsonTest):\n    """"""Tests for the 2.68 microversion in the os-interface API\n",259,refs/changes/48/631948/4
1,1,nova/api/openstack/compute/shelve.py,I4b13483eef42bed91d69eabf1f30762d6866f957,663851,4,CONF nova conf CONF,CONF = nova.conf.CONF,\n        for host_name in host_infos:\n,32,refs/changes/51/663851/4
1,1,nova/compute/manager.py,If3e79cd71b6d0f6e535ff86b27483c137a78fee9,757111,3,LOG warning Failed to remove resource allocation ,                LOG.warning('Failed to remove resource allocation ',"                    'for instance. Error: %(error)s',\n                LOG.warning(\n                    'Failed to remove resource allocation of port %(port_id)s '",7464,refs/changes/11/757111/3
1,1,nova/api/openstack/api_version_request.py,I2f8b4a12a088b9ed96b428eafde2e0c478fb1db5,557145,4, <NUMBER> <NUMBER> Add host hostId to show instance action event API ,    * 2.61 - Add host/hostId to show instance action event API.,    * 2.61 - Add ``host`` and ``hostId`` to show instance action event API.\n    * 2.61 - Add ``host`` and ``hostId`` to show instance action event API.\n,146,refs/changes/45/557145/4
1,1,nova/tests/functional/regressions/test_bug_1732947.py,I1b6e340775379964ff149227355a049ecfa73f0e,684326,1,USE NEUTRON False,    USE_NEUTRON = False,\n    Note that this weigher is supposed to be used via\n,33,refs/changes/26/684326/1
1,1,nova/db/api.py,I7cdb79003b89ac400b169272f77eafdf210b3d17,614672,3,return IMPL block device mapping root by instance context ,"    return IMPL.block_device_mapping_root_by_instance(context,","    return IMPL.block_device_mapping_get_root_by_instance(context,\n    return IMPL.block_device_mapping_get_root_by_instance(context,\n",1244,refs/changes/72/614672/3
1,1,nova/virt/libvirt/migration.py,I91627412744dad65122240f0aeb7a57ee85ba313,551370,20, information for the vif Can you even have different,                # information for the vif? Can you even have different,\n        # Run the legacy volume attachment data migration in a background\n,256,refs/changes/70/551370/20
1,1,nova/compute/manager.py,Iee44ea525deb0b43ae43df3ba08c95ea8a4e317c,742863,4,x for x in block devices if,            x for x in block_devices if,            if driver_block_device.is_block_device_mapping(x)\n            x for x in block_devices\n            if driver_block_device.is_block_device_mapping(x),1917,refs/changes/63/742863/4
1,1,nova/tests/unit/virt/libvirt/test_driver.py,I0ea3a0a1342ef53ed891c145561eb7402f553a8b,728481,4,objects InstanceNUMACell ,                objects.InstanceNUMACell(,"                cpu_pinning={2: 6, 3: 7},\n            objects.InstanceNUMACell(\n                id=2, cpuset=set(), pcpuset=set([0, 1]),",3794,refs/changes/81/728481/4
1,1,nova/virt/libvirt/driver.py,I70310a6769f02ab13c7495ae2075ae6890df728a,687808,1,raise exception InternalError ,                raise exception.InternalError(,"                    reason=m % {'ret': e, 'u': u})\n                raise exception.InvalidCPUInfo(\n                    reason=m % {'ret': e, 'u': u})",8290,refs/changes/08/687808/1
1,1,nova/pci/request.py,I9ba475e91b8283f063db446de74d3e4b2de002c5,619929,2, the given VIF PCI address s vif pci dev address ,"                      "" the given VIF PCI address: %s"", vif_pci_dev_address)","                      vif_pci_dev_address, inst_compute_node_id)\n                      "" the given VIF PCI address: %s on Node(ID=%d)"",\n                      vif_pci_dev_address, inst_compute_node_id)",237,refs/changes/29/619929/2
1,1,nova/tests/functional/test_servers.py,Iefff121640e04abdbb6a4ae546c447f168dc8af9,604084,3, Runs all the server moving tests while the computes has nested trees ,"    """"""Runs all the server moving tests while the computes has nested trees.","    The servers still do not request resources from any child provider though.\n    """"""Runs all the server moving tests while the computes have nested trees.\n    The servers still do not request resources from any child provider though.",4844,refs/changes/84/604084/3
1,1,nova/virt/powervm/disk/driver.py,Id3a2a1df3746120af38b62fdc902c3c0c44c38ee,549053,6,pass,        pass,        raise NotImplementedError()\n        raise NotImplementedError()\n,242,refs/changes/53/549053/6
1,1,nova/tests/functional/api_sample_tests/test_servers.py,Ia3dea78f16cb3c7081714c4db36e20d5ee76ed7d,745906,2,ADMIN API True,    ADMIN_API = True,\nVALID_DISK_CACHEMODES = [\n,682,refs/changes/06/745906/2
1,1,nova/tests/functional/regressions/test_bug_1550919.py,I5619728d5bd684e9167495dd4550ee4f5fbb87a7,591733,12, Source instance directory s exists ,"                        ""Source instance directory %s exists"" %","                        ""Source instance directory %s does not exist"" %\n                        ""Source instance directory %s does not exist"" %\n",271,refs/changes/33/591733/12
1,1,nova/tests/unit/api/openstack/compute/test_user_data.py,I732e40e0e49af02e16cb161d2564381fa34d41cf,559264,1,lambda a k None ,"                      lambda *a, **k: None)","                      lambda c, i, s: None)\n                      lambda c, i, s: None)\n",110,refs/changes/64/559264/1
1,1,nova/conf/hyperv.py,Ib9f735216773224f91ac7f49fbe2eee119670872,652104,5, Path of qemu img command DRIVELETTER PATH TO QEMU IMG COMMAND ,* Path of qemu-img command (DRIVELETTER:\\PATH\\TO\\QEMU-IMG\\COMMAND).,* Path of qemu-img command (DRIVELETTER:\PATH\TO\QEMU-IMG\COMMAND).\n* Path of qemu-img command (DRIVELETTER:\PATH\TO\QEMU-IMG\COMMAND).\n,169,refs/changes/04/652104/5
1,1,nova/cmd/manage.py,Id1003d758b9d35db051c1d591806276dfb521628,637953,7,if not allocations or not allocations get allocations ,        if not allocations or not allocations.get('allocations'):,        else:\n        if allocations and allocations.get('allocations'):\n            # Check to see if the allocation project_id,1877,refs/changes/53/637953/7
1,1,nova/network/neutronv2/api.py,I510e0707b63da98af143448dd46b771f3ef74624,556334,1, This indicates some unexpected error so log it and continue ,                # This indicates some unexpected error so log it and continue.,                # migrate_instance_finish runs.\n                # We don't raise an exception here because we assume that\n                # port bindings will be updated correctly when,2414,refs/changes/34/556334/1
1,1,nova/virt/libvirt/driver.py,I5c346e690148678a2f0dc63f4f516a944c3db8cd,687856,3,instance instance flavor ,"                instance, instance.flavor)","        # sort instance.migration_context.new_resources, and use it bring\n        # destination ordered resources to source host, e.g. vpmem resouce\n        self._sort_migrating_resources(",8027,refs/changes/56/687856/3
1,1,nova/cmd/status.py,I0dc2044286dbe78314c650a92c4654f7f50642d2,603499,2,return upgradecheck UpgradeCheckResult upgradecheck UpgradeCheckCode FAILURE msg ,"                return upgradecheck.UpgradeCheckResult(upgradecheck.UpgradeCheckCode.FAILURE, msg)","                return upgradecheck.Result(upgradecheck.Code.FAILURE, msg)\n                return upgradecheck.Result(upgradecheck.Code.FAILURE, msg)\n",115,refs/changes/99/603499/2
1,1,nova/scheduler/client/report.py,I4d5f26061594fa9863c1110e6152069e44168cc3,577905,2,include project user False ,"                                     include_project_user=False,",\n        primitive = data(obj.obj_to_primitive(target_version='1.7'))\n,1466,refs/changes/05/577905/2
1,1,nova/network/security_group_api.py,Ib129cb399d1521ad6d18fcf0b8ac9fd793888c81,726898,5,utils reraise exc info ,            utils.reraise(*exc_info),            raise e\n            raise e\n,253,refs/changes/98/726898/5
1,1,nova/conductor/tasks/migrate.py,Ia500b105b9ec70c0d8bd38faa084270b825476eb,680394,2, if we reach this point then non of the hosts was new enough for the,        # if we reach this point then non of the hosts was new enough for the,"        reason = (""Exhausted all hosts available during compute service level ""\n        # if we reach this point then none of the hosts was new enough for the\n        # request or we failed to claim resources on every alternate",275,refs/changes/94/680394/2
1,1,nova/api/validation/parameter_types.py,Ic1f2c560a6da815b26fdf770450bbe439d18d4f9,599071,1,def memoize func ,def memoize(func):,def memorize(func):\ndef memorize(func):\n,32,refs/changes/71/599071/1
1,1,nova/tests/unit/api/openstack/compute/test_simple_tenant_usage.py,I3594e66e62b82048062ad4fc502a354e2a7086da,711113,3,def test calculate virtual machine usage hours vm stop before period ,    def test_calculate_virtual_machine_usage_hours_vm_stop_before_period(,    def test_default_behavior_when_stopping_vm_before_search_period(self):\n    def test_default_behavior_when_stopping_vm_before_search_period(self):\n,645,refs/changes/13/711113/3
1,1,nova/virt/powervm/disk/ssp.py,I2691b09d95691915dc1065284d25ad22db41d32b,543023,9,lpar wrap vm get instance wrapper self adapter instance ,"        lpar_wrap = vm.get_instance_wrapper(self._adapter, instance)","        for stg_elem, vios in self._get_bootdisk_iter(instance):\n        for stg_elem, vios in self._get_bootdisk_iter(instance):\n",293,refs/changes/23/543023/9
1,1,nova/tests/unit/virt/libvirt/test_host.py,I2c7b183fcb01f3cb67cb1c8b8bea7aaf5ce424f3,770532,7, listAllDevices as mock list all devices ,"                ""listAllDevices"") as mock_list_all_devices:","            mock.patch.object(\n                self.host.get_connection(), ""listAllDevices""),\n            mock.patch.object(self.host, ""_get_pcinet_info""),",1169,refs/changes/32/770532/7
