label,status,file_dir,change_id,change_num,patch_set,shaped_code,before_code,after_code,line,ref
1,1,nova/compute/api.py,I7f3cbc57a374b2f271018a2f6ef33ef579798db8,780333,1, so this proably works but block evac with vdpa until tested ,        # so this proably works but block evac with vdpa until tested.,"        if instance.has_vdpa_ports():\n        # so this probably works, but we block evac with vdpa until tested.\n        if instance.has_vdpa_ports():",5293,refs/changes/33/780333/1
1,1,nova/cmd/status.py,I0dc2044286dbe78314c650a92c4654f7f50642d2,603499,2,return upgradecheck UpgradeCheckResult upgradecheck UpgradeCheckCode FAILURE msg ,"            return upgradecheck.UpgradeCheckResult(upgradecheck.UpgradeCheckCode.FAILURE, msg)","            return upgradecheck.Result(upgradecheck.Code.FAILURE, msg)\n            return upgradecheck.Result(upgradecheck.Code.FAILURE, msg)\n",115,refs/changes/99/603499/2
1,1,nova/tests/unit/virt/libvirt/test_driver.py,Ib9f735216773224f91ac7f49fbe2eee119670872,652104,5,r neutron physnet bar numa nodes option was defined ,"                r""'\[neutron_physnet_bar\] numa_nodes' option was defined."",","                ""was listed in '[neutron] physnets' but no corresponding ""\n                ""'[neutron_physnet_bar] numa_nodes' option was defined."",\n",15769,refs/changes/04/652104/5
1,1,nova/scheduler/client/report.py,I66d69327d3361825ca0b44b46744b97ea3069eb1,639653,2, There is not enough inventory left on s RP ,                                'There is not enough inventory left on %s RP ',                                'resources.' % (\n                                'There is not enough inventory left on %s '\n                                'resource provider to remove %d amount of %s ',1700,refs/changes/53/639653/2
1,1,nova/virt/libvirt/driver.py,I146cc9d4caafd0abd6b2642edb6eb59cd7e339b7,634549,10,for ns conf in CONF libvirt pmem namespace sizes ,            for ns_conf in CONF.libvirt.pmem_namespace_sizes:,        # pmem name list group by label\n        pmem_names_by_label = collections.defaultdict(list)\n        if CONF.libvirt.pmem_namespaces:,434,refs/changes/49/634549/10
1,1,nova/policies/base.py,I999f8d84e10ff1a57c1ff6b717801b495032e358,645452,8,PROJECT MEMBER OR SYSTEM ADMIN PROJECT MEMBER or SYSTEM ADMIN,PROJECT_MEMBER_OR_SYSTEM_ADMIN = PROJECT_MEMBER + 'or' + SYSTEM_ADMIN,PROJECT_READER_OR_SYSTEM_READER = PROJECT_READER + ' or ' + SYSTEM_READER\nPROJECT_MEMBER_OR_SYSTEM_ADMIN = PROJECT_MEMBER + ' or ' + SYSTEM_ADMIN\nPROJECT_READER_OR_SYSTEM_READER = PROJECT_READER + ' or ' + SYSTEM_READER,35,refs/changes/52/645452/8
1,1,nova/tests/functional/api/openstack/placement/test_direct.py,I075785abcd4f4a8e180959daeadf215b9cd175c8,572576,1,with direct PlacementDirect CONF as url session ,"        with direct.PlacementDirect(CONF) as (url, session):",            resp = client.get('/resource_providers')\n        with direct.PlacementDirect(CONF) as client:\n            resp = client.get('/resource_providers'),48,refs/changes/76/572576/1
1,1,nova/tests/unit/virt/libvirt/test_host.py,I2c7b183fcb01f3cb67cb1c8b8bea7aaf5ce424f3,770532,7,def test get vdpa nodedev by address self ,    def test_get_vdpa_nodedev_by_address(self):,    def test_get_vdpa_device_path(self):\n    def test_get_vdpa_device_path(self):\n,1245,refs/changes/32/770532/7
1,1,nova/conf/scheduler.py,I38f9e0bce5bc58d8b03f562f0de618f1ec38aeb1,556762,2,for hosts with group soft affinity Only a positive value are meaningful as,"  for hosts with group soft affinity. Only a positive value are meaningful, as","* An integer or float value, where the value corresponds to a weight multiplier\n  for hosts with group soft affinity. Only a positive value is meaningful, as\n",521,refs/changes/62/556762/2
1,1,nova/conductor/manager.py,I9358cc3cff44b81b5ce8f9917417282f83860c5b,566470,1, param exception the thrown exception in case of failure ,    :param exception: the thrown exception (in case of failure),    :param exc: the raised exception (in case of failure)\n    :param exc: the raised exception (in case of failure)\n,102,refs/changes/70/566470/1
1,1,nova/virt/block_device.py,I4205c00311f389907dcc390869414687ac03b7f5,682378,1,context instance volume api self volume size wait func ,"                context, instance, volume_api, self.volume_size, wait_func,","                wait_func=wait_func, snapshot=snapshot)\n                context, instance, volume_api, self.volume_size,\n                wait_func=wait_func, snapshot=snapshot)",761,refs/changes/78/682378/1
1,1,nova/tests/unit/virt/libvirt/fakelibvirt.py,I2c7b183fcb01f3cb67cb1c8b8bea7aaf5ce424f3,770532,7,VIR CONNECT LIST NODE DEVICES CAP VDPA <NUMBER>,VIR_CONNECT_LIST_NODE_DEVICES_CAP_VDPA = 131072,VIR_CONNECT_LIST_NODE_DEVICES_CAP_VDPA = 1 << 17\nVIR_CONNECT_LIST_NODE_DEVICES_CAP_VDPA = 1 << 17\n,184,refs/changes/32/770532/7
1,1,nova/scheduler/client/report.py,Ie991d4b53e9bb5e7ec26da99219178ab7695abf6,591810,2, param source consumer uuid the UUID of the consumer that s allocation,        :param source_consumer_uuid: the UUID of the consumer that's allocation,                                     allocations\n        :param source_consumer_uuid: the UUID of the consumer from which\n                                     allocations are moving,1826,refs/changes/10/591810/2
1,1,nova/scheduler/filters/core_filter.py,Ibfbfdae9e6ec93f772631a84e8969f4e11da8aee,673496,1, allocation ratios either per host in the nova conf ,                    'allocation ratios either per host in the nova.conf',                    'filter_scheduler driver. Operators should define cpu '\n                    'allocation ratios either per host in the nova.conf '\n                    'or via the placement API.'),40,refs/changes/96/673496/1
1,1,nova/virt/libvirt/driver.py,Ia8a35ecff20911471a5c353c0b55be86f2e4e21a,631237,1, param cells An list of LibvirtConfigCapsNUMACell objects ,        :param cells: An list of ``LibvirtConfigCapsNUMACell`` objects.,        :param cells: A list of ``LibvirtConfigCapsNUMACell`` objects.\n        :param cells: A list of ``LibvirtConfigCapsNUMACell`` objects.\n,6422,refs/changes/37/631237/1
1,1,nova/image/glance.py,I20913201cf945a7fde1f9e6264c415e1235db7b9,738738,2, param write image Write the image file provided by image chunks ,        :param write_image: Write the image file provided by image_chunks.,        :param dst_path: Filepath to transfer the image file to.\n        :param dst_path: Filepath to transfer the image file to.\n,342,refs/changes/38/738738/2
1,1,nova/utils.py,I00d29e9fd80e6b8f7ba3bbd8e82dde9d4cb1522f,555282,1, param host The name of the host to which the server is evacuated ,    :param host: The name of the host to which the server is evacuated.,    :param host: The name of the compute host.\n    :param host: The name of the compute host.\n,1391,refs/changes/82/555282/1
1,1,nova/scheduler/weights/ram.py,I6e15c6507d037ffe263a460441858ed454b02504,628163,1,return utils get weight multiplier host state cpu ,"        return utils.get_weight_multiplier(host_state, 'cpu')","            CONF.filter_scheduler.ram_weight_multiplier)\n        return utils.get_weight_multiplier(\n            host_state, 'ram_weight_multiplier',",35,refs/changes/63/628163/1
1,1,nova/tests/unit/virt/powervm/tasks/test_storage.py,I2691b09d95691915dc1065284d25ad22db41d32b,543023,9, Management Partition is VIOS and Novalink hosted storage,        # Management Partition is VIOS and Novalink hosted storage,        # Management Partition is VIOS and NovaLink hosted storage\n        # Management Partition is VIOS and NovaLink hosted storage\n,233,refs/changes/23/543023/9
1,1,nova/scheduler/utils.py,I32d9704fe19bc85e06a613b6dffb99f00003315e,641289,1, There are more than one numbered request group in the ,"                ""There are more than one numbered request group in the ""","                ""There is more than one numbered request group in the ""\n                ""There is more than one numbered request group in the ""\n",311,refs/changes/89/641289/1
1,1,nova/policies/remote_consoles.py,Ic81da0ebc23d6526c5ca2d9d98159e07f3e53822,716484,2,This policy is for POST remote consoles API and below Server actions APIs,This policy is for POST /remote-consoles API and below Server actions APIs,This policy is for ``POST /remote-consoles`` API and below Server actions APIs\nThis policy is for ``POST /remote-consoles`` API and below Server actions APIs\n,30,refs/changes/84/716484/2
1,1,nova/scheduler/filters/core_filter.py,Ibfbfdae9e6ec93f772631a84e8969f4e11da8aee,673496,1, filter scheduler driver Operators should define cpu ,                    'filter_scheduler driver. Operators should define cpu',                    'using the Placement service when using the '\n                    'filter_scheduler driver. Operators should define cpu '\n                    'allocation ratios either per host in the nova.conf ',39,refs/changes/96/673496/1
1,1,nova/tests/functional/api_sample_tests/test_attach_interfaces.py,I09420ff7134874dfe4dc399931c7740e81ecc2d0,631948,4, Tests for the <NUMBER> <NUMBER> microversion in the os attach interfaces API,"    """"""Tests for the 2.68 microversion in the os-attach-interfaces API","class AttachInterfacesSampleV268JsonTest(AttachInterfacesSampleJsonTest):\n    """"""Tests for the 2.68 microversion in the os-interface API\n",259,refs/changes/48/631948/4
1,1,nova/db/api.py,I7cdb79003b89ac400b169272f77eafdf210b3d17,614672,3,return IMPL block device mapping root by instance context ,"    return IMPL.block_device_mapping_root_by_instance(context,","    return IMPL.block_device_mapping_get_root_by_instance(context,\n    return IMPL.block_device_mapping_get_root_by_instance(context,\n",1244,refs/changes/72/614672/3
1,1,nova/tests/functional/test_servers.py,Iefff121640e04abdbb6a4ae546c447f168dc8af9,604084,3, Runs all the server moving tests while the computes has nested trees ,"    """"""Runs all the server moving tests while the computes has nested trees.","    The servers still do not request resources from any child provider though.\n    """"""Runs all the server moving tests while the computes have nested trees.\n    The servers still do not request resources from any child provider though.",4844,refs/changes/84/604084/3
1,1,nova/conf/hyperv.py,Ib9f735216773224f91ac7f49fbe2eee119670872,652104,5, Path of qemu img command DRIVELETTER PATH TO QEMU IMG COMMAND ,* Path of qemu-img command (DRIVELETTER:\\PATH\\TO\\QEMU-IMG\\COMMAND).,* Path of qemu-img command (DRIVELETTER:\PATH\TO\QEMU-IMG\COMMAND).\n* Path of qemu-img command (DRIVELETTER:\PATH\TO\QEMU-IMG\COMMAND).\n,169,refs/changes/04/652104/5
1,1,nova/cmd/manage.py,Id1003d758b9d35db051c1d591806276dfb521628,637953,7,if not allocations or not allocations get allocations ,        if not allocations or not allocations.get('allocations'):,        else:\n        if allocations and allocations.get('allocations'):\n            # Check to see if the allocation project_id,1877,refs/changes/53/637953/7
1,1,nova/cmd/status.py,I0dc2044286dbe78314c650a92c4654f7f50642d2,603499,2,return upgradecheck UpgradeCheckResult upgradecheck UpgradeCheckCode FAILURE msg ,"                return upgradecheck.UpgradeCheckResult(upgradecheck.UpgradeCheckCode.FAILURE, msg)","                return upgradecheck.Result(upgradecheck.Code.FAILURE, msg)\n                return upgradecheck.Result(upgradecheck.Code.FAILURE, msg)\n",115,refs/changes/99/603499/2
