label,status,file_dir,change_id,change_num,patch_set,shaped_code,before_code,after_code,line,ref
1,1,nova/compute/api.py,I7f3cbc57a374b2f271018a2f6ef33ef579798db8,780333,1, so this proably works but block evac with vdpa until tested ,        # so this proably works but block evac with vdpa until tested.,"        if instance.has_vdpa_ports():\n        # so this probably works, but we block evac with vdpa until tested.\n        if instance.has_vdpa_ports():",5293,refs/changes/33/780333/1
1,1,nova/api/openstack/placement/objects/resource_provider.py,I89d2892fabb6273bfa793f4a06dced80b68e93d5,588350,1,LOG debug s d of d returned d matches ,"            LOG.debug(""%s (%d of %d) returned %d matches"",","                      str(request), str(suffix), len(alloc_reqs))\n            LOG.debug(""%s (suffix '%s') returned %d matches"",\n                      str(request), str(suffix), len(alloc_reqs))",4043,refs/changes/50/588350/1
1,1,nova/policies/base.py,I999f8d84e10ff1a57c1ff6b717801b495032e358,645452,8,PROJECT MEMBER OR SYSTEM ADMIN PROJECT MEMBER or SYSTEM ADMIN,PROJECT_MEMBER_OR_SYSTEM_ADMIN = PROJECT_MEMBER + 'or' + SYSTEM_ADMIN,PROJECT_READER_OR_SYSTEM_READER = PROJECT_READER + ' or ' + SYSTEM_READER\nPROJECT_MEMBER_OR_SYSTEM_ADMIN = PROJECT_MEMBER + ' or ' + SYSTEM_ADMIN\nPROJECT_READER_OR_SYSTEM_READER = PROJECT_READER + ' or ' + SYSTEM_READER,35,refs/changes/52/645452/8
1,1,nova/tests/unit/virt/libvirt/test_host.py,I2c7b183fcb01f3cb67cb1c8b8bea7aaf5ce424f3,770532,7,def test get vdpa nodedev by address self ,    def test_get_vdpa_nodedev_by_address(self):,    def test_get_vdpa_device_path(self):\n    def test_get_vdpa_device_path(self):\n,1245,refs/changes/32/770532/7
1,1,nova/conf/scheduler.py,I38f9e0bce5bc58d8b03f562f0de618f1ec38aeb1,556762,2,for hosts with group soft affinity Only a positive value are meaningful as,"  for hosts with group soft affinity. Only a positive value are meaningful, as","* An integer or float value, where the value corresponds to a weight multiplier\n  for hosts with group soft affinity. Only a positive value is meaningful, as\n",521,refs/changes/62/556762/2
1,1,nova/conductor/manager.py,I9358cc3cff44b81b5ce8f9917417282f83860c5b,566470,1, param exception the thrown exception in case of failure ,    :param exception: the thrown exception (in case of failure),    :param exc: the raised exception (in case of failure)\n    :param exc: the raised exception (in case of failure)\n,102,refs/changes/70/566470/1
1,1,nova/scheduler/filters/core_filter.py,Ibfbfdae9e6ec93f772631a84e8969f4e11da8aee,673496,1, allocation ratios either per host in the nova conf ,                    'allocation ratios either per host in the nova.conf',                    'filter_scheduler driver. Operators should define cpu '\n                    'allocation ratios either per host in the nova.conf '\n                    'or via the placement API.'),40,refs/changes/96/673496/1
1,1,nova/scheduler/weights/ram.py,I6e15c6507d037ffe263a460441858ed454b02504,628163,1,return utils get weight multiplier host state cpu ,"        return utils.get_weight_multiplier(host_state, 'cpu')","            CONF.filter_scheduler.ram_weight_multiplier)\n        return utils.get_weight_multiplier(\n            host_state, 'ram_weight_multiplier',",35,refs/changes/63/628163/1
1,1,nova/scheduler/utils.py,I32d9704fe19bc85e06a613b6dffb99f00003315e,641289,1, There are more than one numbered request group in the ,"                ""There are more than one numbered request group in the ""","                ""There is more than one numbered request group in the ""\n                ""There is more than one numbered request group in the ""\n",311,refs/changes/89/641289/1
1,1,nova/policies/remote_consoles.py,Ic81da0ebc23d6526c5ca2d9d98159e07f3e53822,716484,2,This policy is for POST remote consoles API and below Server actions APIs,This policy is for POST /remote-consoles API and below Server actions APIs,This policy is for ``POST /remote-consoles`` API and below Server actions APIs\nThis policy is for ``POST /remote-consoles`` API and below Server actions APIs\n,30,refs/changes/84/716484/2
1,1,nova/tests/unit/policies/test_attach_interfaces.py,I8a91db6c13710b693b3b4a3d002fd2ac09fcf3f3,705126,8,It defines the set of context with scopped token,    It defines the set of context with scopped token,    It defines the set of context with scoped token\n    It defines the set of context with scoped token\n,114,refs/changes/26/705126/8
1,1,nova/scheduler/filters/core_filter.py,Ibfbfdae9e6ec93f772631a84e8969f4e11da8aee,673496,1, filter scheduler driver Operators should define cpu ,                    'filter_scheduler driver. Operators should define cpu',                    'using the Placement service when using the '\n                    'filter_scheduler driver. Operators should define cpu '\n                    'allocation ratios either per host in the nova.conf ',39,refs/changes/96/673496/1
1,1,nova/api/openstack/api_version_request.py,I2f8b4a12a088b9ed96b428eafde2e0c478fb1db5,557145,4, <NUMBER> <NUMBER> Add host hostId to show instance action event API ,    * 2.61 - Add host/hostId to show instance action event API.,    * 2.61 - Add ``host`` and ``hostId`` to show instance action event API.\n    * 2.61 - Add ``host`` and ``hostId`` to show instance action event API.\n,146,refs/changes/45/557145/4
1,1,nova/db/api.py,I7cdb79003b89ac400b169272f77eafdf210b3d17,614672,3,return IMPL block device mapping root by instance context ,"    return IMPL.block_device_mapping_root_by_instance(context,","    return IMPL.block_device_mapping_get_root_by_instance(context,\n    return IMPL.block_device_mapping_get_root_by_instance(context,\n",1244,refs/changes/72/614672/3
1,1,nova/tests/functional/test_servers.py,Iefff121640e04abdbb6a4ae546c447f168dc8af9,604084,3, Runs all the server moving tests while the computes has nested trees ,"    """"""Runs all the server moving tests while the computes has nested trees.","    The servers still do not request resources from any child provider though.\n    """"""Runs all the server moving tests while the computes have nested trees.\n    The servers still do not request resources from any child provider though.",4844,refs/changes/84/604084/3
1,1,nova/conf/hyperv.py,Ib9f735216773224f91ac7f49fbe2eee119670872,652104,5, Path of qemu img command DRIVELETTER PATH TO QEMU IMG COMMAND ,* Path of qemu-img command (DRIVELETTER:\\PATH\\TO\\QEMU-IMG\\COMMAND).,* Path of qemu-img command (DRIVELETTER:\PATH\TO\QEMU-IMG\COMMAND).\n* Path of qemu-img command (DRIVELETTER:\PATH\TO\QEMU-IMG\COMMAND).\n,169,refs/changes/04/652104/5
1,1,nova/cmd/manage.py,Id1003d758b9d35db051c1d591806276dfb521628,637953,7,if not allocations or not allocations get allocations ,        if not allocations or not allocations.get('allocations'):,        else:\n        if allocations and allocations.get('allocations'):\n            # Check to see if the allocation project_id,1877,refs/changes/53/637953/7
