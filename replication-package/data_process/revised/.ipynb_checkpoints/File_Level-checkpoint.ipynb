{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb20c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scripts Information:\n",
    "#Input: File level dataset. Files: \"Nova.csv\",\"Ironic.csv\", \"Base.csv\"\n",
    "#Output: File level result. File: \"csv_revised_fileLevel.csv\"\n",
    "#Description: This script is used to generate the result for predicting lines to be revised for RQ2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "from scipy import sparse\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import time, pickle, math, warnings, os, operator\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import math\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# read dataset\n",
    "data_nova = pd.read_csv('./dataset/fileLevel/Nova.csv', dtype=None, sep=',').to_numpy()\n",
    "data_ironic = pd.read_csv('./dataset/fileLevel/Ironic.csv', dtype=None, sep=',').to_numpy()\n",
    "data_base = pd.read_csv('./dataset/fileLevel/Base.csv', dtype=None, sep=',').to_numpy()\n",
    "\n",
    "# path that saves all trained models\n",
    "model_path = './dataset/ml-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2395869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate training/test datset\n",
    "def getDatasetFromRawData(project_source, data, bias):\n",
    "    row_data = data[0:,3]\n",
    "    row_data_Y = data[0:,0]\n",
    "    row_data_deletions = data[0:,6]\n",
    "    row_data_additions = data[0:,7]\n",
    "    row_data_changedLine = data[0:,8]\n",
    "  \n",
    "    Y_train = []\n",
    "    is_comment = 0\n",
    "    not_comment = 0\n",
    "    for element in row_data_Y:\n",
    "        if(element == 0):\n",
    "            Y_train.append(False)\n",
    "            not_comment += 1\n",
    "        else:\n",
    "            Y_train.append(True)\n",
    "            is_comment += 1\n",
    "    Y_train = np.array(Y_train)\n",
    "\n",
    "    #finding a index that wouldn't separate file in same changeId into both training dataset and test dataset\n",
    "    first = int(len(data)*0.6)\n",
    "    divider = int(len(data)*0.2) + first + bias\n",
    "    data_count_vect = CountVectorizer(min_df=2, max_df=0.5)\n",
    "    train_row_data = row_data[:divider]\n",
    "    test_row_data = row_data[divider:]\n",
    "    train_row_data_deletions = row_data_deletions[:divider]\n",
    "    test_row_data_deletions = row_data_deletions[divider:]\n",
    "    train_row_data_additions = row_data_additions[:divider]\n",
    "    test_row_data_additions = row_data_additions[divider:]\n",
    "    train_row_data_changedLine = row_data_changedLine[:divider]\n",
    "    test_row_data_changedLine = row_data_changedLine[divider:]\n",
    "    data_train_counts = data_count_vect.fit_transform(train_row_data)\n",
    "    data_test_counts = data_count_vect.transform(test_row_data)\n",
    "    final_train_X = np.hstack((data_train_counts.toarray(),train_row_data_deletions[:,None]))\n",
    "    final_train_X = np.hstack((final_train_X,train_row_data_additions[:,None]))\n",
    "    final_train_X = np.hstack((final_train_X,train_row_data_changedLine[:,None]))\n",
    "    final_test_X = np.hstack((data_test_counts.toarray(),test_row_data_deletions[:,None]))\n",
    "    final_test_X = np.hstack((final_test_X,test_row_data_additions[:,None]))\n",
    "    final_test_X = np.hstack((final_test_X,test_row_data_changedLine[:,None]))\n",
    "    final_train_y = Y_train[:divider]\n",
    "    final_test_y = Y_train[divider:]\n",
    "    del data_train_counts,data_test_counts,train_row_data,test_row_data,data,row_data,row_data_Y \n",
    "    return final_train_X,final_train_y,final_test_X,final_test_y,divider,data_count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284d73c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show file level prediction result\n",
    "def printResult(x, y, model):\n",
    "    print(\"AUC:\",roc_auc_score(y, model.predict_proba(x)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c8aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train random forest model\n",
    "def trainRFmodel(project,rf_train_X,rf_train_y,rf_test_X,rf_test_y,seed,bias):\n",
    "    print(\"RF:\"+project)\n",
    "    train_rf_model_path = model_path+'/RQ2_2_rf_'+project+'-'+str(seed)+str(bias)+'.pkl'\n",
    "    if not os.path.exists(train_rf_model_path):\n",
    "        rf = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=seed)\n",
    "        rf_X, rf_y = SMOTE(k_neighbors=10, random_state=seed).fit_resample(rf_train_X, rf_train_y)\n",
    "        rf.fit(rf_X,rf_y)\n",
    "        rf_ouput = open(train_rf_model_path, 'wb')\n",
    "        pickle.dump(rf,rf_ouput)\n",
    "        print(\"finish to creat a new rf model\")\n",
    "    else:\n",
    "        with open(train_rf_model_path,'rb') as f:\n",
    "            rf = pickle.load(f)\n",
    "    printResult(rf_test_X,rf_test_y,rf)\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train Naive Bayes model\n",
    "def trainNBmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    print(\"NB:\"+project)\n",
    "    train_nb_model_path = model_path+'/smote_abstr_number_df_2_nb_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_nb_model_path):\n",
    "        nb = MultinomialNB()\n",
    "        nb.fit(train_X,train_y)\n",
    "        nb_ouput = open(train_nb_model_path, 'wb')\n",
    "        pickle.dump(nb,nb_ouput)\n",
    "        print(\"finish to creat a new nb model\")\n",
    "    else:\n",
    "        with open(train_nb_model_path,'rb') as f:\n",
    "            nb = pickle.load(f)\n",
    "    printResult(test_X,test_y,nb)\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f7bbec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression model\n",
    "def trainLGmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    print(\"LG:\"+project)\n",
    "    train_lg_model_path = model_path+'/RQ2_2_lg_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_lg_model_path):\n",
    "        lg = linear_model.LogisticRegression(penalty='l2', C=1, solver = 'newton-cg', random_state=seed)\n",
    "        lg.fit(train_X,train_y)\n",
    "        lg_ouput = open(train_lg_model_path, 'wb')\n",
    "        pickle.dump(lg,lg_ouput)\n",
    "        print(\"finish to creat a new lg model\")\n",
    "    else:\n",
    "        with open(train_lg_model_path,'rb') as f:\n",
    "            lg = pickle.load(f)\n",
    "    printResult(test_X,test_y,lg)\n",
    "    return lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899501a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train decision tree model\n",
    "def trainDTmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    print(\"DT:\"+project)\n",
    "    train_dt_model_path = model_path+'/RQ2_2_dt_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_dt_model_path):\n",
    "        dt = DecisionTreeClassifier(random_state=seed)\n",
    "        dt.fit(train_X,train_y)\n",
    "        dt_ouput = open(train_dt_model_path, 'wb')\n",
    "        pickle.dump(dt,dt_ouput)\n",
    "        print(\"finish to creat a new dt model\")\n",
    "    else:\n",
    "        with open(train_dt_model_path,'rb') as f:\n",
    "            dt = pickle.load(f)\n",
    "    printResult(test_X,test_y,dt)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ba544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train KNN model\n",
    "def trainKnnmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    print(\"KNN:\"+project)\n",
    "    train_knn_model_path = model_path+'/smote_abstr_number_df_2_knn_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_knn_model_path):\n",
    "        knn = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "        knn.fit(train_X, train_y)\n",
    "        knn_ouput = open(train_knn_model_path, 'wb')\n",
    "        pickle.dump(knn,knn_ouput)\n",
    "        print(\"finish to creat a new knn model\")\n",
    "    else:\n",
    "        with open(train_knn_model_path,'rb') as f:\n",
    "            knn = pickle.load(f)\n",
    "    printResult(test_X,test_y,knn)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cc07b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train random guessing model\n",
    "def trainDMmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    train_dm_model_path = model_path+'/RQ2_2_dm_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_dm_model_path):\n",
    "        dm = DummyClassifier(strategy='stratified',random_state=seed)\n",
    "        dm.fit(train_X, train_y)\n",
    "        dm_ouput = open(train_dm_model_path, 'wb')\n",
    "        pickle.dump(dm,dm_ouput)\n",
    "        print(\"finish to creat a new dm model\")\n",
    "    else:\n",
    "        with open(train_dm_model_path,'rb') as f:\n",
    "            dm = pickle.load(f)\n",
    "    printResult(test_X,test_y,dm)\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b959a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResult(project_source,seed,projectName,data,bias):\n",
    "    projectName = projectName\n",
    "    #RF\n",
    "    train_X, train_y, test_X, test_y,divider,data_count_vect = getDatasetFromRawData(project_source,data, bias)\n",
    "    rf = trainRFmodel(projectName,train_X, train_y, test_X, test_y,seed, bias)\n",
    "    lg = trainLGmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    nb = trainNBmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    dt = trainDTmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    knn = trainKnnmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    dm = trainDMmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    return rf,lg,nb,dt,knn,dm,test_X,test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd954ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate csv files for data evaluation at path: ./dataset/csv/csv_revised_fileLevel.csv\n",
    "def outputCsv():\n",
    "    csv_path = './dataset/csv/csv_revised_fileLevel.csv'\n",
    "    csv_file = open(csv_path,\"w\")\n",
    "    fieldnames = ['Technique','Datasets','Measure','Value']\n",
    "    csv_writer = csv.DictWriter(csv_file,quoting=csv.QUOTE_NONE,escapechar='', fieldnames= fieldnames) \n",
    "    rf_nova,lg_nova,nb_nova,dt_nova,knn_nova,dm_nova,test_X_nova, test_y_nova = getResult(\"openstack\",2,\"nova\",data_nova,5)\n",
    "    rf_ironic,lg_ironic,nb_ironic,dt_ironic,knn_ironic,dm_ironic,test_X_ironic, test_y_ironic = getResult(\"openstack\",2,\"ironic\",data_ironic,-4)\n",
    "    rf_base,lg_base,nb_base,dt_base,knn_base,dm_base,test_X_base, test_y_base = getResult(\"qt\",2,\"base\",data_base,6)\n",
    "    result = []\n",
    "    result = generateResult(result,\"nova\",rf_nova,lg_nova,nb_nova,knn_nova,dt_nova,dm_nova,test_X_nova, test_y_nova)\n",
    "    result = generateResult(result,\"ironic\",rf_ironic,lg_ironic,nb_ironic,knn_ironic,dt_ironic,dm_ironic,test_X_ironic, test_y_ironic)\n",
    "    result = generateResult(result,\"base\",rf_base,lg_base,nb_base,knn_base,dt_base,dm_base,test_X_base, test_y_base)\n",
    "    csv_writer.writeheader()\n",
    "    for row in result:\n",
    "        csv_writer.writerow(row)\n",
    "    return result\n",
    "\n",
    "def generateResult(result, project,rf,lg,nb,knn,dt,dm,x,y):\n",
    "    result = generateResultList(result, project,\"RF\",rf,x, y)\n",
    "    result = generateResultList(result, project,\"LG\",lg,x, y)\n",
    "    result = generateResultList(result, project,\"NB\",nb,x, y)\n",
    "    result = generateResultList(result, project,\"DT\",dt,x, y)\n",
    "    result = generateResultList(result, project,\"KNN\",knn,x, y)\n",
    "    result = generateResultList(result, project,\"Random Guessing\",dm,x, y)\n",
    "    return result\n",
    "\n",
    "def generateResultList(result,project,name,model ,x, y):\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'AUC','Value':roc_auc_score(y, model.predict_proba(x)[:,1])})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'Precision','Value':precision_score(y, model.predict(x))})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'Recall','Value':recall_score(y, model.predict(x))})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'F1 measure','Value':f1_score(y, model.predict(x))})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'MCC','Value':matthews_corrcoef(y, model.predict(x))})\n",
    "    tn, fp, fn, tp = confusion_matrix(y, model.predict(x)).ravel()\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'true negative','Value':tn})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'false positive','Value':fp})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'false negative','Value':fn})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'true positive','Value':tp})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3885145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7674415538557487\n",
      "Precision: 0.5156695156695157\n",
      "Recall: 0.40401785714285715\n",
      "F1: 0.4530663329161451\n",
      "MCC: 0.3492059087776338\n",
      "Confusion matrix: \n",
      " [[1777  170]\n",
      " [ 267  181]]\n",
      "AUC: 0.6242817475603493\n",
      "Precision: 0.36674816625916873\n",
      "Recall: 0.33482142857142855\n",
      "F1: 0.35005834305717615\n",
      "MCC: 0.20911434367467477\n",
      "Confusion matrix: \n",
      " [[1688  259]\n",
      " [ 298  150]]\n",
      "AUC: 0.584426475713552\n",
      "Precision: 0.33098591549295775\n",
      "Recall: 0.31473214285714285\n",
      "F1: 0.32265446224256294\n",
      "MCC: 0.17167831345157145\n",
      "Confusion matrix: \n",
      " [[1662  285]\n",
      " [ 307  141]]\n",
      "dummy seed:2\n",
      "AUC: 0.4894652487343165\n",
      "Precision: 0.1766304347826087\n",
      "Recall: 0.29017857142857145\n",
      "F1: 0.2195945945945946\n",
      "MCC: -0.017807959703329\n",
      "Confusion matrix: \n",
      " [[1341  606]\n",
      " [ 318  130]]\n",
      "AUC: 0.6779517743757546\n",
      "Precision: 0.3813953488372093\n",
      "Recall: 0.4120603015075377\n",
      "F1: 0.39613526570048313\n",
      "MCC: 0.2005539299285651\n",
      "Confusion matrix: \n",
      " [[512 133]\n",
      " [117  82]]\n",
      "AUC: 0.5928362743952319\n",
      "Precision: 0.35454545454545455\n",
      "Recall: 0.39195979899497485\n",
      "F1: 0.3723150357995227\n",
      "MCC: 0.16612613190273592\n",
      "Confusion matrix: \n",
      " [[503 142]\n",
      " [121  78]]\n",
      "AUC: 0.5373923882980796\n",
      "Precision: 0.2777777777777778\n",
      "Recall: 0.3768844221105528\n",
      "F1: 0.3198294243070362\n",
      "MCC: 0.0678527906416606\n",
      "Confusion matrix: \n",
      " [[450 195]\n",
      " [124  75]]\n",
      "dummy seed:2\n",
      "AUC: 0.49328425071091897\n",
      "Precision: 0.22596153846153846\n",
      "Recall: 0.23618090452261306\n",
      "F1: 0.23095823095823095\n",
      "MCC: -0.013230328899216482\n",
      "Confusion matrix: \n",
      " [[484 161]\n",
      " [152  47]]\n",
      "AUC: 0.689435095121355\n",
      "Precision: 0.46537396121883656\n",
      "Recall: 0.23076923076923078\n",
      "F1: 0.3085399449035813\n",
      "MCC: 0.23279862966165274\n",
      "Confusion matrix: \n",
      " [[3133  193]\n",
      " [ 560  168]]\n",
      "AUC: 0.5407115434174965\n",
      "Precision: 0.37681159420289856\n",
      "Recall: 0.21428571428571427\n",
      "F1: 0.2732049036777583\n",
      "MCC: 0.173297502328493\n",
      "Confusion matrix: \n",
      " [[3068  258]\n",
      " [ 572  156]]\n",
      "AUC: 0.5628213112804213\n",
      "Precision: 0.34177215189873417\n",
      "Recall: 0.22252747252747251\n",
      "F1: 0.2695507487520799\n",
      "MCC: 0.1537608833412604\n",
      "Confusion matrix: \n",
      " [[3014  312]\n",
      " [ 566  162]]\n",
      "dummy seed:2\n",
      "AUC: 0.49829432443683797\n",
      "Precision: 0.1767180925666199\n",
      "Recall: 0.17307692307692307\n",
      "F1: 0.17487855655794585\n",
      "MCC: -0.00343930136825771\n",
      "Confusion matrix: \n",
      " [[2739  587]\n",
      " [ 602  126]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.7674427003081663},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.5156695156695157},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.40401785714285715},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.4530663329161451},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.3492059087776338},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 1777},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 170},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 267},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 181},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.6242817475603493},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.36674816625916873},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.33482142857142855},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.35005834305717615},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.20911434367467477},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 1688},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 259},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 298},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 150},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.584426475713552},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.33098591549295775},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.31473214285714285},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.32265446224256294},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.17167831345157145},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 1662},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 285},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 307},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 141},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.4894652487343165},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.1766304347826087},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.29017857142857145},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.2195945945945946},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': -0.017807959703329},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 1341},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 606},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 318},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 130},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.6779478789295313},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.3813953488372093},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.4120603015075377},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.39613526570048313},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.2005539299285651},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 512},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 133},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 117},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 82},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.5928362743952319},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.35454545454545455},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.39195979899497485},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.3723150357995227},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.16612613190273592},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 503},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 142},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 121},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 78},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.5373923882980796},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.2777777777777778},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.3768844221105528},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.3198294243070362},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.0678527906416606},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 450},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 195},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 124},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 75},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.49328425071091897},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.22596153846153846},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.23618090452261306},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.23095823095823095},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': -0.013230328899216482},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 484},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 161},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 152},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 47},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.6894342691283463},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.46537396121883656},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.23076923076923078},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.3085399449035813},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.23279862966165274},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 3133},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 193},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 560},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 168},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.5407115434174965},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.37681159420289856},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.21428571428571427},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.2732049036777583},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.173297502328493},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 3068},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 258},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 572},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 156},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.5628213112804213},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.34177215189873417},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.22252747252747251},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.2695507487520799},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.1537608833412604},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 3014},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 312},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 566},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 162},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.49829432443683797},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.1767180925666199},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.17307692307692307},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.17487855655794585},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': -0.00343930136825771},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 2739},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 587},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 602},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 126}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputCsv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9afbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
