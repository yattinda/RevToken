{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f8585fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scripts Information:\n",
    "#Input: File level dataset. Files: \"Nova.csv\",\"Ironic.csv\", \"Base.csv\"\n",
    "#Output: File level result. File: \"csv_commented_fileLevel.csv\"\n",
    "#Description: This script is used to generate the result for predicting files to should receive comments for RQ2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "from scipy import sparse\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import time, pickle, math, warnings, os, operator\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import math\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# read dataset\n",
    "data_nova = pd.read_csv('./dataset/fileLevel/Nova.csv', dtype=None, sep=',').to_numpy()\n",
    "data_ironic = pd.read_csv('./dataset/fileLevel/Ironic.csv', dtype=None, sep=',').to_numpy()\n",
    "data_base = pd.read_csv('./dataset/fileLevel/Base.csv', dtype=None, sep=',').to_numpy()\n",
    "\n",
    "# path that saves all trained models\n",
    "model_path = './dataset/ml-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37370f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate training/test datset\n",
    "def getDatasetFromRawData(project_source, data, bias):\n",
    "    row_data = data[0:,3]\n",
    "    row_data_Y = data[0:,0]\n",
    "    if project_source == \"qt\":\n",
    "        row_data_deletions = data[0:,6]\n",
    "        row_data_additions = data[0:,7]\n",
    "        row_data_changedLine = data[0:,8]\n",
    "    else:\n",
    "        row_data_deletions = data[0:,7]\n",
    "        row_data_additions = data[0:,8]\n",
    "        row_data_changedLine = data[0:,9]\n",
    "    Y_train = []\n",
    "    is_comment = 0\n",
    "    not_comment = 0\n",
    "    for element in row_data_Y:\n",
    "        if(element == 0):\n",
    "            Y_train.append(False)\n",
    "            not_comment += 1\n",
    "        else:\n",
    "            Y_train.append(True)\n",
    "            is_comment += 1\n",
    "    Y_train = np.array(Y_train)\n",
    "    #finding a index that wouldn't separate file in same changeId into both training dataset and test dataset\n",
    "    first = int(len(data)*0.6)\n",
    "    divider = int(len(data)*0.2) + first + bias\n",
    "    data_count_vect = CountVectorizer(min_df=2, max_df=0.5)\n",
    "    train_row_data = row_data[:divider]\n",
    "    test_row_data = row_data[divider:]\n",
    "    train_row_data_deletions = row_data_deletions[:divider]\n",
    "    test_row_data_deletions = row_data_deletions[divider:]\n",
    "    train_row_data_additions = row_data_additions[:divider]\n",
    "    test_row_data_additions = row_data_additions[divider:]\n",
    "    train_row_data_changedLine = row_data_changedLine[:divider]\n",
    "    test_row_data_changedLine = row_data_changedLine[divider:]\n",
    "    data_train_counts = data_count_vect.fit_transform(train_row_data)\n",
    "    data_test_counts = data_count_vect.transform(test_row_data)\n",
    "    final_train_X = np.hstack((data_train_counts.toarray(),train_row_data_deletions[:,None]))\n",
    "    final_train_X = np.hstack((final_train_X,train_row_data_additions[:,None]))\n",
    "    final_train_X = np.hstack((final_train_X,train_row_data_changedLine[:,None]))\n",
    "\n",
    "    final_test_X = np.hstack((data_test_counts.toarray(),test_row_data_deletions[:,None]))\n",
    "    final_test_X = np.hstack((final_test_X,test_row_data_additions[:,None]))\n",
    "    final_test_X = np.hstack((final_test_X,test_row_data_changedLine[:,None]))\n",
    "    final_train_y = Y_train[:divider]\n",
    "    final_test_y = Y_train[divider:]\n",
    "\n",
    "    del data_train_counts,data_test_counts,train_row_data,test_row_data,data,row_data,row_data_Y\n",
    "    return final_train_X,final_train_y,final_test_X,final_test_y,divider,data_count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be021fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show file level prediction result\n",
    "def printResult(x, y, model):\n",
    "    print(\"AUC:\",roc_auc_score(y, model.predict_proba(x)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e0c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train random forest model\n",
    "def trainRFmodel(project,rf_train_X,rf_train_y,rf_test_X,rf_test_y,seed, bias):\n",
    "    print(\"RF:\"+project)\n",
    "    train_rf_model_path = model_path+'/smote_abstr_number_df_2_rf_'+project+'-'+str(seed)+str(bias)+'.pkl'\n",
    "    if not os.path.exists(train_rf_model_path):\n",
    "        rf = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=seed)\n",
    "        rf_X, rf_y = SMOTE(k_neighbors=10, random_state=seed).fit_resample(rf_train_X, rf_train_y)\n",
    "        rf.fit(rf_X,rf_y)\n",
    "        rf_ouput = open(train_rf_model_path, 'wb')\n",
    "        pickle.dump(rf,rf_ouput)\n",
    "        print(\"finish to creat a new rf model\")\n",
    "    else:\n",
    "        with open(train_rf_model_path,'rb') as f:\n",
    "            rf = pickle.load(f)\n",
    "    printResult(rf_test_X,rf_test_y,rf)\n",
    "    return rf\n",
    "\n",
    "# TN FP\n",
    "# FN TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be71cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression model\n",
    "def trainLGmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    print(\"LG:\"+project)\n",
    "    train_lg_model_path = model_path+'/smote_abstr_number_df_2_lg_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_lg_model_path):\n",
    "        lg = linear_model.LogisticRegression(penalty='l2', C=1, solver = 'newton-cg', random_state=seed)\n",
    "        lg.fit(train_X,train_y)\n",
    "        lg_ouput = open(train_lg_model_path, 'wb')\n",
    "        pickle.dump(lg,lg_ouput)\n",
    "        print(\"finish to creat a new lg model\")\n",
    "    else:\n",
    "        with open(train_lg_model_path,'rb') as f:\n",
    "            lg = pickle.load(f)\n",
    "    printResult(test_X,test_y,lg)\n",
    "    return lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b353e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train Naive Bayes model\n",
    "def trainNBmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    print(\"NB:\"+project)\n",
    "    train_nb_model_path = model_path+'/smote_abstr_number_df_2_nb_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_nb_model_path):\n",
    "        nb = MultinomialNB()\n",
    "        nb.fit(train_X,train_y)\n",
    "        nb_ouput = open(train_nb_model_path, 'wb')\n",
    "        pickle.dump(nb,nb_ouput)\n",
    "        print(\"finish to creat a new nb model\")\n",
    "    else:\n",
    "        with open(train_nb_model_path,'rb') as f:\n",
    "            nb = pickle.load(f)\n",
    "    printResult(test_X,test_y,nb)\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3d774cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train Decision Tree model\n",
    "def trainDTmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    print(\"DT:\"+project)\n",
    "    train_dt_model_path = model_path+'/smote_abstr_number_df_2_dt_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_dt_model_path):\n",
    "        dt = DecisionTreeClassifier(random_state=seed)\n",
    "        dt.fit(train_X,train_y)\n",
    "        dt_ouput = open(train_dt_model_path, 'wb')\n",
    "        pickle.dump(dt,dt_ouput)\n",
    "        print(\"finish to creat a new dt model\")\n",
    "    else:\n",
    "        with open(train_dt_model_path,'rb') as f:\n",
    "            dt = pickle.load(f)\n",
    "    printResult(test_X,test_y,dt)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2b47672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train KNN model\n",
    "def trainKnnmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    print(\"KNN:\"+project)\n",
    "    train_knn_model_path = model_path+'/smote_abstr_number_df_2_knn_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_knn_model_path):\n",
    "        knn = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "        knn.fit(train_X, train_y)\n",
    "        knn_ouput = open(train_knn_model_path, 'wb')\n",
    "        pickle.dump(knn,knn_ouput)\n",
    "        print(\"finish to creat a new knn model\")\n",
    "    else:\n",
    "        with open(train_knn_model_path,'rb') as f:\n",
    "            knn = pickle.load(f)\n",
    "    printResult(test_X,test_y,knn)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e4aa014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train random guessing model\n",
    "def trainDMmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    train_dm_model_path = model_path+'/RQ2_1_dm_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_dm_model_path):\n",
    "        dm = DummyClassifier(strategy='stratified',random_state=seed)\n",
    "        dm.fit(train_X, train_y)\n",
    "        dm_ouput = open(train_dm_model_path, 'wb')\n",
    "        pickle.dump(dm,dm_ouput)\n",
    "        print(\"finish to creat a new dm model\")\n",
    "    else:\n",
    "        with open(train_dm_model_path,'rb') as f:\n",
    "            dm = pickle.load(f)\n",
    "    printResult(test_X,test_y,dm)\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97c6c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResult(project_source,seed,projectName,data,bias):\n",
    "    projectName = projectName\n",
    "    #RF\n",
    "    train_X, train_y, test_X, test_y,divider,data_count_vect = getDatasetFromRawData(project_source,data, bias)\n",
    "    rf = trainRFmodel(projectName,train_X, train_y, test_X, test_y,seed, bias)\n",
    "    lg = trainLGmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    nb = trainNBmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    dt = trainDTmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    knn = trainKnnmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    dm = trainDMmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    return rf,lg,nb,dt,knn,dm,test_X,test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b93b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate csv files for data evaluation at path: ./dataset/csv/csv_commented_fileLevel.csv\n",
    "def outputCsv():\n",
    "    csv_path = './dataset/csv/csv_commented_fileLevel.csv'\n",
    "    csv_file = open(csv_path,\"w\")\n",
    "    fieldnames = ['Technique','Datasets','Measure','Value']\n",
    "    csv_writer = csv.DictWriter(csv_file,quoting=csv.QUOTE_NONE,escapechar='', fieldnames= fieldnames) \n",
    "    rf_nova,lg_nova,nb_nova,dt_nova,knn_nova,dm_nova,test_X_nova, test_y_nova = getResult(\"openstack\",2,\"nova\",data_nova,5)\n",
    "    rf_ironic,lg_ironic,nb_ironic,dt_ironic,knn_ironic,dm_ironic,test_X_ironic, test_y_ironic = getResult(\"openstack\",2,\"ironic\",data_ironic,-4)\n",
    "    rf_base,lg_base,nb_base,dt_base,knn_base,dm_base,test_X_base, test_y_base = getResult(\"qt\",2,\"base\",data_base,6)\n",
    "    result = []\n",
    "    result = generateResult(result,\"nova\",rf_nova,lg_nova,nb_nova,knn_nova,dt_nova,dm_nova,test_X_nova, test_y_nova)\n",
    "    result = generateResult(result,\"ironic\",rf_ironic,lg_ironic,nb_ironic,knn_ironic,dt_ironic,dm_ironic,test_X_ironic, test_y_ironic)\n",
    "    result = generateResult(result,\"base\",rf_base,lg_base,nb_base,knn_base,dt_base,dm_base,test_X_base, test_y_base)\n",
    "    csv_writer.writeheader()\n",
    "    for row in result:\n",
    "        csv_writer.writerow(row)\n",
    "    return result\n",
    "\n",
    "def generateResult(result, project,rf,lg,nb,knn,dt,dm,x,y):\n",
    "    result = generateResultList(result, project,\"RF\",rf,x, y)\n",
    "    result = generateResultList(result, project,\"LG\",lg,x, y)\n",
    "    result = generateResultList(result, project,\"NB\",nb,x, y)\n",
    "    result = generateResultList(result, project,\"DT\",dt,x, y)\n",
    "    result = generateResultList(result, project,\"KNN\",knn,x, y)\n",
    "    result = generateResultList(result, project,\"Random Guessing\",dm,x, y)\n",
    "    return result\n",
    "\n",
    "def generateResultList(result,project,name,model ,x, y):\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'AUC','Value':roc_auc_score(y, model.predict_proba(x)[:,1])})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'Precision','Value':precision_score(y, model.predict(x))})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'Recall','Value':recall_score(y, model.predict(x))})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'F1 measure','Value':f1_score(y, model.predict(x))})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'MCC','Value':matthews_corrcoef(y, model.predict(x))})\n",
    "    tn, fp, fn, tp = confusion_matrix(y, model.predict(x)).ravel()\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'true negative','Value':tn})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'false positive','Value':fp})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'false negative','Value':fn})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'true positive','Value':tp})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e37306",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputCsv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81e1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "原始单元格格式",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
